{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural classification\n",
    "As has been proven by [Wang (2017)](https://arxiv.org/abs/1705.00648), neural classifiers carry better results than non-neural classifiers when detecting fake news. However, it is unknown how well neural networks classify fake news when using previously mentioned text embeddings. \n",
    "In this notebook, the second research question will be answered: *how well do neural network architecture classify fake news compared to non-neural classification algorithms?*\n",
    "\n",
    "<hr>\n",
    "\n",
    "## On the usage of neural networks\n",
    "Literature on CNNs and Bi-LSTMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Reshape, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Set offline mode for plotly\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "# The DataLoader class gives access to pretrained vectors from the Liar dataset\n",
    "from data_loader import DataLoader\n",
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = data.get_dfs()\n",
    "\n",
    "# Recode labels from 6 to 3\n",
    "def recode(label):\n",
    "    if label == 'false' or label == 'pants-fire' or label == 'barely-true':\n",
    "        return 0\n",
    "    elif label == 'true' or label == 'mostly-true':\n",
    "        return 2\n",
    "    elif label == 'half-true':\n",
    "        return 1\n",
    "\n",
    "for dataset in general.keys():\n",
    "    general[dataset]['label'] = general[dataset]['label'].apply(lambda label: recode(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Bidirectional LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = data.get_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max-pooled BERT embeddings from RQ1\n",
    "def max_pool(statement):\n",
    "    if len(statement) > 1:\n",
    "        return [row.max() for row in np.transpose([[token_row.max() for token_row in np.transpose(np.array(sentence))] for sentence in statement])]\n",
    "    else:\n",
    "        return [token_row.max() for token_row in np.transpose(statement[0])]\n",
    "\n",
    "max_pooled_bert = {\n",
    "    dataset: pd.DataFrame(list(bert[dataset].statement.apply(lambda statement: max_pool(statement)).values))\n",
    "    for dataset in bert.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_score(X_train, X_test, X_validation, y_train = general['train']['label'], y_test = general['test']['label'], y_validation = general['validation']['label'], reshape = True):\n",
    "    # Rearrange data types    \n",
    "    params = locals().copy()    \n",
    "    inputs = {\n",
    "        dataset: np.array(params[dataset])\n",
    "        for dataset in params.keys()\n",
    "    }\n",
    "    \n",
    "    for dataset in inputs.keys():\n",
    "        if dataset[0:1] == 'X' and reshape:\n",
    "            # Reshape datasets from 2D to 3D\n",
    "            inputs[dataset] = np.reshape(inputs[dataset], (inputs[dataset].shape[0], inputs[dataset].shape[1], 1))\n",
    "        elif dataset[0:1] == 'y':\n",
    "            inputs[dataset] = np_utils.to_categorical(np.array(inputs[dataset]), 3)\n",
    "    \n",
    "    # Set model parameters\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    input_shape = X_train.shape\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, input_shape = input_shape)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile('sgd', 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    \n",
    "    # Fit the training set over the model and correct on the validation set\n",
    "    model.fit(inputs['X_train'], inputs['y_train'],\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            validation_data = (inputs['X_validation'], inputs['y_validation']))\n",
    "    \n",
    "    # Get score over the test set\n",
    "    score, acc = model.evaluate(inputs['X_test'], inputs['y_test'])\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-05-21 12:40:37,047 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-05-21 12:40:37,448 From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2019-05-21 12:40:37,537 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 829s 81ms/step - loss: 1.0743 - acc: 0.4087 - val_loss: 1.0423 - val_acc: 0.4798\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 844s 82ms/step - loss: 1.0632 - acc: 0.4300 - val_loss: 1.0392 - val_acc: 0.4798\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 838s 82ms/step - loss: 1.0590 - acc: 0.4354 - val_loss: 1.0408 - val_acc: 0.4798\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 840s 82ms/step - loss: 1.0592 - acc: 0.4354 - val_loss: 1.0432 - val_acc: 0.4798\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 809s 79ms/step - loss: 1.0591 - acc: 0.4337 - val_loss: 1.0395 - val_acc: 0.4798\n",
      "1265/1265 [==============================] - 16s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43715415052745654"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bilstm_score(max_pooled_bert['train'], max_pooled_bert['test'], max_pooled_bert['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the condensed datasets from RQ1 do not perform well when using a neural classifier. The next step is trying out a padding approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 69s 7ms/step - loss: 1.1184 - acc: 0.4145 - val_loss: 1.0170 - val_acc: 0.5093\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0597 - acc: 0.4532 - val_loss: 1.0196 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0432 - acc: 0.4707 - val_loss: 1.0158 - val_acc: 0.5125\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0362 - acc: 0.4775 - val_loss: 1.0134 - val_acc: 0.5117\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0279 - acc: 0.4821 - val_loss: 1.0089 - val_acc: 0.5164\n",
      "1265/1265 [==============================] - 2s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 46s 4ms/step - loss: 1.1094 - acc: 0.4181 - val_loss: 1.0184 - val_acc: 0.4907\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0558 - acc: 0.4556 - val_loss: 1.0125 - val_acc: 0.5125\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0428 - acc: 0.4693 - val_loss: 1.0125 - val_acc: 0.5070\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0332 - acc: 0.4863 - val_loss: 1.0140 - val_acc: 0.5008\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0303 - acc: 0.4824 - val_loss: 1.0051 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 1s 594us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.1187 - acc: 0.4151 - val_loss: 1.0248 - val_acc: 0.5109\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0541 - acc: 0.4529 - val_loss: 1.0166 - val_acc: 0.5125\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0422 - acc: 0.4718 - val_loss: 1.0122 - val_acc: 0.5078\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0347 - acc: 0.4808 - val_loss: 1.0118 - val_acc: 0.5047\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0292 - acc: 0.4889 - val_loss: 1.0056 - val_acc: 0.5109\n",
      "1265/1265 [==============================] - 1s 969us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.1133 - acc: 0.4260 - val_loss: 1.0178 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0581 - acc: 0.4538 - val_loss: 1.0119 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0404 - acc: 0.4719 - val_loss: 1.0130 - val_acc: 0.5039\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0340 - acc: 0.4828 - val_loss: 1.0065 - val_acc: 0.5055\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0276 - acc: 0.4863 - val_loss: 1.0027 - val_acc: 0.5125\n",
      "1265/1265 [==============================] - 1s 799us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.1089 - acc: 0.4181 - val_loss: 1.0162 - val_acc: 0.5031\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0551 - acc: 0.4594 - val_loss: 1.0202 - val_acc: 0.5047\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0381 - acc: 0.4771 - val_loss: 1.0091 - val_acc: 0.5078\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0320 - acc: 0.4829 - val_loss: 1.0067 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0247 - acc: 0.4908 - val_loss: 1.0029 - val_acc: 0.5016\n",
      "1265/1265 [==============================] - 1s 846us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.1186 - acc: 0.4209 - val_loss: 1.0138 - val_acc: 0.5062\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0519 - acc: 0.4614 - val_loss: 1.0098 - val_acc: 0.5008\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 24s 2ms/step - loss: 1.0398 - acc: 0.4782 - val_loss: 1.0044 - val_acc: 0.5062\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0280 - acc: 0.4896 - val_loss: 1.0080 - val_acc: 0.5101\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0241 - acc: 0.4943 - val_loss: 1.0050 - val_acc: 0.5125\n",
      "1265/1265 [==============================] - 1s 929us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.1218 - acc: 0.4208 - val_loss: 1.0134 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0544 - acc: 0.4600 - val_loss: 1.0069 - val_acc: 0.5202\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0398 - acc: 0.4773 - val_loss: 1.0043 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0296 - acc: 0.4862 - val_loss: 1.0027 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0265 - acc: 0.4872 - val_loss: 0.9985 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 1s 1ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.1138 - acc: 0.4279 - val_loss: 1.0142 - val_acc: 0.5109\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0477 - acc: 0.4682 - val_loss: 1.0073 - val_acc: 0.5164\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0368 - acc: 0.4805 - val_loss: 1.0111 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0281 - acc: 0.4867 - val_loss: 1.0011 - val_acc: 0.5218\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0280 - acc: 0.4947 - val_loss: 1.0041 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 3s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 80s 8ms/step - loss: 1.1205 - acc: 0.4236 - val_loss: 1.0263 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0541 - acc: 0.4649 - val_loss: 1.0081 - val_acc: 0.5187\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0391 - acc: 0.4769 - val_loss: 1.0083 - val_acc: 0.5218\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0296 - acc: 0.4863 - val_loss: 1.0060 - val_acc: 0.5047\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0239 - acc: 0.4927 - val_loss: 1.0026 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 3s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 86s 8ms/step - loss: 1.1171 - acc: 0.4152 - val_loss: 1.0107 - val_acc: 0.5078\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0496 - acc: 0.4637 - val_loss: 1.0054 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0413 - acc: 0.4780 - val_loss: 1.0082 - val_acc: 0.5179\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0297 - acc: 0.4904 - val_loss: 1.0004 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0234 - acc: 0.4949 - val_loss: 0.9993 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 3s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 92s 9ms/step - loss: 1.1165 - acc: 0.4206 - val_loss: 1.0214 - val_acc: 0.5148\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0553 - acc: 0.4656 - val_loss: 1.0178 - val_acc: 0.5109\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0350 - acc: 0.4852 - val_loss: 1.0104 - val_acc: 0.5101\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0312 - acc: 0.4890 - val_loss: 1.0051 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0229 - acc: 0.4910 - val_loss: 1.0055 - val_acc: 0.5101\n",
      "1265/1265 [==============================] - 3s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 91s 9ms/step - loss: 1.1168 - acc: 0.4210 - val_loss: 1.0127 - val_acc: 0.5047\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 37s 4ms/step - loss: 1.0508 - acc: 0.4668 - val_loss: 1.0166 - val_acc: 0.5086\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0364 - acc: 0.4793 - val_loss: 1.0032 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 32s 3ms/step - loss: 1.0281 - acc: 0.4893 - val_loss: 1.0000 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0228 - acc: 0.4973 - val_loss: 1.0013 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 98s 10ms/step - loss: 1.1218 - acc: 0.4131 - val_loss: 1.0302 - val_acc: 0.4984\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0546 - acc: 0.4616 - val_loss: 1.0226 - val_acc: 0.5008\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 36s 4ms/step - loss: 1.0387 - acc: 0.4726 - val_loss: 1.0115 - val_acc: 0.5164\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0314 - acc: 0.4861 - val_loss: 1.0049 - val_acc: 0.5164\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0245 - acc: 0.4940 - val_loss: 1.0055 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 103s 10ms/step - loss: 1.1113 - acc: 0.4235 - val_loss: 1.0184 - val_acc: 0.5234\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0534 - acc: 0.4643 - val_loss: 1.0104 - val_acc: 0.5226\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 36s 3ms/step - loss: 1.0409 - acc: 0.4802 - val_loss: 1.0079 - val_acc: 0.5117\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 36s 4ms/step - loss: 1.0321 - acc: 0.4882 - val_loss: 1.0040 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 37s 4ms/step - loss: 1.0239 - acc: 0.5000 - val_loss: 1.0034 - val_acc: 0.5140\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 101s 10ms/step - loss: 1.1158 - acc: 0.4191 - val_loss: 1.0152 - val_acc: 0.5226\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0550 - acc: 0.4584 - val_loss: 1.0119 - val_acc: 0.5249\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0378 - acc: 0.4787 - val_loss: 1.0057 - val_acc: 0.5296\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0310 - acc: 0.4812 - val_loss: 1.0030 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0227 - acc: 0.4948 - val_loss: 0.9970 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 109s 11ms/step - loss: 1.1228 - acc: 0.4128 - val_loss: 1.0199 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0554 - acc: 0.4577 - val_loss: 1.0189 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0387 - acc: 0.4784 - val_loss: 1.0061 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0341 - acc: 0.4836 - val_loss: 1.0074 - val_acc: 0.5195\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0242 - acc: 0.4958 - val_loss: 1.0025 - val_acc: 0.5140\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 111s 11ms/step - loss: 1.1078 - acc: 0.4219 - val_loss: 1.0287 - val_acc: 0.4984\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0534 - acc: 0.4610 - val_loss: 1.0140 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0422 - acc: 0.4721 - val_loss: 1.0134 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0265 - acc: 0.4914 - val_loss: 1.0109 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0268 - acc: 0.4949 - val_loss: 1.0093 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 118s 12ms/step - loss: 1.1146 - acc: 0.4152 - val_loss: 1.0207 - val_acc: 0.5031\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0577 - acc: 0.4632 - val_loss: 1.0113 - val_acc: 0.5249\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0401 - acc: 0.4759 - val_loss: 1.0133 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 43s 4ms/step - loss: 1.0335 - acc: 0.4819 - val_loss: 1.0071 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 43s 4ms/step - loss: 1.0266 - acc: 0.4901 - val_loss: 1.0044 - val_acc: 0.5234\n",
      "1265/1265 [==============================] - 6s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 110s 11ms/step - loss: 1.1089 - acc: 0.4237 - val_loss: 1.0265 - val_acc: 0.5140\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.0583 - acc: 0.4500 - val_loss: 1.0147 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0430 - acc: 0.4778 - val_loss: 1.0108 - val_acc: 0.5241\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0318 - acc: 0.4808 - val_loss: 1.0067 - val_acc: 0.5226\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0303 - acc: 0.4843 - val_loss: 1.0078 - val_acc: 0.5241\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 114s 11ms/step - loss: 1.1008 - acc: 0.4262 - val_loss: 1.0131 - val_acc: 0.5070\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0570 - acc: 0.4583 - val_loss: 1.0094 - val_acc: 0.5117\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 46s 5ms/step - loss: 1.0434 - acc: 0.4738 - val_loss: 1.0143 - val_acc: 0.5148\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0325 - acc: 0.4833 - val_loss: 1.0063 - val_acc: 0.5187\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0260 - acc: 0.4900 - val_loss: 1.0022 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 120s 12ms/step - loss: 1.1036 - acc: 0.4241 - val_loss: 1.0248 - val_acc: 0.4938\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0551 - acc: 0.4624 - val_loss: 1.0112 - val_acc: 0.5195\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0423 - acc: 0.4752 - val_loss: 1.0161 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0296 - acc: 0.4879 - val_loss: 1.0038 - val_acc: 0.5140\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0270 - acc: 0.4869 - val_loss: 1.0063 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 117s 11ms/step - loss: 1.1012 - acc: 0.4247 - val_loss: 1.0202 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.0566 - acc: 0.4576 - val_loss: 1.0107 - val_acc: 0.5164\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0400 - acc: 0.4775 - val_loss: 1.0086 - val_acc: 0.5218\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0354 - acc: 0.4865 - val_loss: 1.0027 - val_acc: 0.5265\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0266 - acc: 0.4919 - val_loss: 1.0065 - val_acc: 0.5257\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 130s 13ms/step - loss: 1.0999 - acc: 0.4246 - val_loss: 1.0188 - val_acc: 0.4992\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0588 - acc: 0.4596 - val_loss: 1.0145 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0415 - acc: 0.4750 - val_loss: 1.0089 - val_acc: 0.5156\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0319 - acc: 0.4848 - val_loss: 1.0036 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0260 - acc: 0.4872 - val_loss: 1.0034 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 133s 13ms/step - loss: 1.1086 - acc: 0.4064 - val_loss: 1.0186 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 65s 6ms/step - loss: 1.0563 - acc: 0.4585 - val_loss: 1.0152 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0411 - acc: 0.4723 - val_loss: 1.0108 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0383 - acc: 0.4797 - val_loss: 1.0096 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0304 - acc: 0.4826 - val_loss: 1.0036 - val_acc: 0.5148\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 136s 13ms/step - loss: 1.0960 - acc: 0.4262 - val_loss: 1.0261 - val_acc: 0.4774\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 67s 7ms/step - loss: 1.0572 - acc: 0.4566 - val_loss: 1.0126 - val_acc: 0.5202\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0404 - acc: 0.4806 - val_loss: 1.0154 - val_acc: 0.5023\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0341 - acc: 0.4777 - val_loss: 1.0074 - val_acc: 0.5148\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0242 - acc: 0.4919 - val_loss: 1.0010 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 7s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 132s 13ms/step - loss: 1.0877 - acc: 0.4269 - val_loss: 1.0218 - val_acc: 0.5055\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.0545 - acc: 0.4550 - val_loss: 1.0150 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0455 - acc: 0.4722 - val_loss: 1.0101 - val_acc: 0.5101\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0369 - acc: 0.4793 - val_loss: 1.0025 - val_acc: 0.5109\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0328 - acc: 0.4806 - val_loss: 1.0035 - val_acc: 0.5218\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 134s 13ms/step - loss: 1.0966 - acc: 0.4192 - val_loss: 1.0159 - val_acc: 0.5093\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 70s 7ms/step - loss: 1.0535 - acc: 0.4648 - val_loss: 1.0140 - val_acc: 0.5179\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.0407 - acc: 0.4737 - val_loss: 1.0057 - val_acc: 0.5148\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0344 - acc: 0.4890 - val_loss: 1.0030 - val_acc: 0.5234\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0281 - acc: 0.4929 - val_loss: 1.0092 - val_acc: 0.5218\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 141s 14ms/step - loss: 1.0952 - acc: 0.4262 - val_loss: 1.0169 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 73s 7ms/step - loss: 1.0548 - acc: 0.4621 - val_loss: 1.0139 - val_acc: 0.5078\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0452 - acc: 0.4678 - val_loss: 1.0068 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 60s 6ms/step - loss: 1.0353 - acc: 0.4783 - val_loss: 1.0042 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 60s 6ms/step - loss: 1.0292 - acc: 0.4875 - val_loss: 0.9996 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 8s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 138s 14ms/step - loss: 1.0938 - acc: 0.4192 - val_loss: 1.0201 - val_acc: 0.5156\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.0523 - acc: 0.4641 - val_loss: 1.0134 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0419 - acc: 0.4745 - val_loss: 1.0075 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0364 - acc: 0.4815 - val_loss: 1.0043 - val_acc: 0.5218\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0280 - acc: 0.4910 - val_loss: 1.0054 - val_acc: 0.5078\n",
      "1265/1265 [==============================] - 8s 7ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 144s 14ms/step - loss: 1.1040 - acc: 0.4251 - val_loss: 1.0204 - val_acc: 0.4938\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 77s 8ms/step - loss: 1.0522 - acc: 0.4651 - val_loss: 1.0147 - val_acc: 0.5016\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0452 - acc: 0.4717 - val_loss: 1.0112 - val_acc: 0.5117\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0349 - acc: 0.4837 - val_loss: 1.0142 - val_acc: 0.5062\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0292 - acc: 0.4872 - val_loss: 0.9990 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 9s 7ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 147s 14ms/step - loss: 1.0870 - acc: 0.4226 - val_loss: 1.0187 - val_acc: 0.5117\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 79s 8ms/step - loss: 1.0529 - acc: 0.4603 - val_loss: 1.0116 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 73s 7ms/step - loss: 1.0456 - acc: 0.4740 - val_loss: 1.0122 - val_acc: 0.5055\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.0368 - acc: 0.4828 - val_loss: 1.0076 - val_acc: 0.5125\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 72s 7ms/step - loss: 1.0324 - acc: 0.4843 - val_loss: 1.0060 - val_acc: 0.5226\n",
      "1265/1265 [==============================] - 8s 6ms/step\n",
      "CPU times: user 8h 57s, sys: 2h 14min 29s, total: 10h 15min 26s\n",
      "Wall time: 2h 44min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Store accuracies\n",
    "accuracies = {\n",
    "    padding_len: 0.0 for padding_len in list(range(5,36))\n",
    "}\n",
    "\n",
    "concatenated_bert = {\n",
    "    dataset: [np.concatenate(np.array(statement)) for statement in bert[dataset].statement]\n",
    "    for dataset in bert.keys()\n",
    "}\n",
    "\n",
    "for max_len in accuracies.keys():\n",
    "    padded_bert = {\n",
    "        dataset: sequence.pad_sequences(concatenated_bert[dataset], maxlen = max_len, dtype = float)\n",
    "        for dataset in concatenated_bert.keys()\n",
    "    }\n",
    "    \n",
    "    accuracies[max_len] = get_bilstm_score(padded_bert['train'], padded_bert['test'], padded_bert['validation'], reshape = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{5: 0.513043478637816,\n",
       "  6: 0.5122529648038239,\n",
       "  7: 0.5075098817998712,\n",
       "  8: 0.5083003953747127,\n",
       "  9: 0.49407114631573673,\n",
       "  10: 0.5098814233018476,\n",
       "  11: 0.507509881752753,\n",
       "  12: 0.5035573126299108,\n",
       "  13: 0.4996047434599503,\n",
       "  14: 0.5027667987488004,\n",
       "  15: 0.507509881752753,\n",
       "  16: 0.5090909091144682,\n",
       "  17: 0.5067193679187609,\n",
       "  18: 0.5114624509227135,\n",
       "  19: 0.5098814233018476,\n",
       "  20: 0.5162055336203971,\n",
       "  21: 0.5193675893097527,\n",
       "  22: 0.5193675893097527,\n",
       "  23: 0.5233201584797131,\n",
       "  24: 0.5217391304583417,\n",
       "  25: 0.5106719371358397,\n",
       "  26: 0.5106719367824524,\n",
       "  27: 0.5177865616417685,\n",
       "  28: 0.5075098817998712,\n",
       "  29: 0.513043478637816,\n",
       "  30: 0.5043478264639029,\n",
       "  31: 0.5162055336203971,\n",
       "  32: 0.5075098817998712,\n",
       "  33: 0.5114624509698318,\n",
       "  34: 0.513833992471808,\n",
       "  35: 0.5075098817998712},\n",
       " {5: 0.5098814233018476,\n",
       "  6: 0.5098814229484603,\n",
       "  7: 0.49723320160458684,\n",
       "  8: 0.5090909091144682,\n",
       "  9: 0.5051383399445077,\n",
       "  10: 0.505928854131887,\n",
       "  11: 0.498814229272571,\n",
       "  12: 0.5114624509698318,\n",
       "  13: 0.4940711466220057,\n",
       "  14: 0.49169960512002936,\n",
       "  15: 0.4996047431065631,\n",
       "  16: 0.5027667984425315,\n",
       "  17: 0.4956521739366026,\n",
       "  18: 0.5067193679658791,\n",
       "  19: 0.5067193676124919,\n",
       "  20: 0.5043478264167846,\n",
       "  21: 0.5146245063058001,\n",
       "  22: 0.5256916999816894,\n",
       "  23: 0.5201581031437448,\n",
       "  24: 0.515415019786405,\n",
       "  25: 0.5169960478077764,\n",
       "  26: 0.521739130811729,\n",
       "  27: 0.5185770751223734,\n",
       "  28: 0.5154150201397922,\n",
       "  29: 0.5209486169777369,\n",
       "  30: 0.5027667987959187,\n",
       "  31: 0.5011857711279345,\n",
       "  32: 0.5154150201397922,\n",
       "  33: 0.5083003956338633,\n",
       "  34: 0.5075098817998712,\n",
       "  35: 0.5185770754286423},\n",
       " {5: 0.5035573122765236,\n",
       "  6: 0.5027667984425315,\n",
       "  7: 0.5090909094207372,\n",
       "  8: 0.49090909128603727,\n",
       "  9: 0.5098814233018476,\n",
       "  10: 0.505928854131887,\n",
       "  11: 0.5075098817998712,\n",
       "  12: 0.5035573123236419,\n",
       "  13: 0.5003952572468241,\n",
       "  14: 0.488537549784061,\n",
       "  15: 0.5075098817998712,\n",
       "  16: 0.5035573122765236,\n",
       "  17: 0.5003952572468241,\n",
       "  18: 0.5122529648038239,\n",
       "  19: 0.5051383402507766,\n",
       "  20: 0.5177865616417685,\n",
       "  21: 0.5106719371358397,\n",
       "  22: 0.5019762849619266,\n",
       "  23: 0.5106719368295707,\n",
       "  24: 0.5083003956338633,\n",
       "  25: 0.5146245063058001,\n",
       "  26: 0.5146245063058001,\n",
       "  27: 0.5177865616417685,\n",
       "  28: 0.5067193676596102,\n",
       "  29: 0.5098814233018476,\n",
       "  30: 0.5146245063058001,\n",
       "  31: 0.5138339921184208,\n",
       "  32: 0.5043478264639029,\n",
       "  33: 0.507509881446484,\n",
       "  34: 0.5154150201397922,\n",
       "  35: 0.5067193679658791},\n",
       " {5: 0.49249011895402145,\n",
       "  6: 0.5098814229484603,\n",
       "  7: 0.5019762849148083,\n",
       "  8: 0.505928854131887,\n",
       "  9: 0.5059288537784998,\n",
       "  10: 0.4996047434599503,\n",
       "  11: 0.5035573126299108,\n",
       "  12: 0.4996047434599503,\n",
       "  13: 0.5003952572468241,\n",
       "  14: 0.4893280636180531,\n",
       "  15: 0.5035573126299108,\n",
       "  16: 0.49802371543857893,\n",
       "  17: 0.513043478637816,\n",
       "  18: 0.5019762846085394,\n",
       "  19: 0.5106719371358397,\n",
       "  20: 0.5114624509227135,\n",
       "  21: 0.5122529648038239,\n",
       "  22: 0.515415019786405,\n",
       "  23: 0.5154150201397922,\n",
       "  24: 0.522529644645721,\n",
       "  25: 0.505138340297895,\n",
       "  26: 0.5169960478077764,\n",
       "  27: 0.5201581031437448,\n",
       "  28: 0.5106719371358397,\n",
       "  29: 0.4996047434599503,\n",
       "  30: 0.5169960478077764,\n",
       "  31: 0.5067193676124919,\n",
       "  32: 0.5146245063058001,\n",
       "  33: 0.5043478264639029,\n",
       "  34: 0.5043478261105157,\n",
       "  35: 0.5106719367824524},\n",
       " {5: 0.505138340297895,\n",
       "  6: 0.505928854131887,\n",
       "  7: 0.4948616604559978,\n",
       "  8: 0.5051383399445077,\n",
       "  9: 0.498814229272571,\n",
       "  10: 0.5122529647567056,\n",
       "  11: 0.49723320195797405,\n",
       "  12: 0.5146245063058001,\n",
       "  13: 0.505928854131887,\n",
       "  14: 0.4940711466220057,\n",
       "  15: 0.5106719368295707,\n",
       "  16: 0.5106719367824524,\n",
       "  17: 0.5027667987959187,\n",
       "  18: 0.5059288537784998,\n",
       "  19: 0.5083003956338633,\n",
       "  20: 0.5098814233018476,\n",
       "  21: 0.5138339921184208,\n",
       "  22: 0.5027667987959187,\n",
       "  23: 0.5146245059995312,\n",
       "  24: 0.5059288540847687,\n",
       "  25: 0.5130434783315471,\n",
       "  26: 0.5169960478077764,\n",
       "  27: 0.5114624509698318,\n",
       "  28: 0.505928854131887,\n",
       "  29: 0.505928854131887,\n",
       "  30: 0.5098814233018476,\n",
       "  31: 0.5114624509698318,\n",
       "  32: 0.5059288537784998,\n",
       "  33: 0.5130434783315471,\n",
       "  34: 0.49723320195797405,\n",
       "  35: 0.5114624509698318}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round1, round2, round3, round4, round5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Round 0",
         "type": "scatter",
         "uid": "36b39775-a328-4c54-a3ca-4455c6dc01d6",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.513043478637816,
          0.5122529648038239,
          0.5075098817998712,
          0.5083003953747127,
          0.49407114631573673,
          0.5098814233018476,
          0.507509881752753,
          0.5035573126299108,
          0.4996047434599503,
          0.5027667987488004,
          0.507509881752753,
          0.5090909091144682,
          0.5067193679187609,
          0.5114624509227135,
          0.5098814233018476,
          0.5162055336203971,
          0.5193675893097527,
          0.5193675893097527,
          0.5233201584797131,
          0.5217391304583417,
          0.5106719371358397,
          0.5106719367824524,
          0.5177865616417685,
          0.5075098817998712,
          0.513043478637816,
          0.5043478264639029,
          0.5162055336203971,
          0.5075098817998712,
          0.5114624509698318,
          0.513833992471808,
          0.5075098817998712
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 1",
         "type": "scatter",
         "uid": "05ff3bde-811d-43d5-8421-2f3acd734853",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5098814233018476,
          0.5098814229484603,
          0.49723320160458684,
          0.5090909091144682,
          0.5051383399445077,
          0.505928854131887,
          0.498814229272571,
          0.5114624509698318,
          0.4940711466220057,
          0.49169960512002936,
          0.4996047431065631,
          0.5027667984425315,
          0.4956521739366026,
          0.5067193679658791,
          0.5067193676124919,
          0.5043478264167846,
          0.5146245063058001,
          0.5256916999816894,
          0.5201581031437448,
          0.515415019786405,
          0.5169960478077764,
          0.521739130811729,
          0.5185770751223734,
          0.5154150201397922,
          0.5209486169777369,
          0.5027667987959187,
          0.5011857711279345,
          0.5154150201397922,
          0.5083003956338633,
          0.5075098817998712,
          0.5185770754286423
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 2",
         "type": "scatter",
         "uid": "332e414a-c977-4eeb-894a-69644b06f03d",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5035573122765236,
          0.5027667984425315,
          0.5090909094207372,
          0.49090909128603727,
          0.5098814233018476,
          0.505928854131887,
          0.5075098817998712,
          0.5035573123236419,
          0.5003952572468241,
          0.488537549784061,
          0.5075098817998712,
          0.5035573122765236,
          0.5003952572468241,
          0.5122529648038239,
          0.5051383402507766,
          0.5177865616417685,
          0.5106719371358397,
          0.5019762849619266,
          0.5106719368295707,
          0.5083003956338633,
          0.5146245063058001,
          0.5146245063058001,
          0.5177865616417685,
          0.5067193676596102,
          0.5098814233018476,
          0.5146245063058001,
          0.5138339921184208,
          0.5043478264639029,
          0.507509881446484,
          0.5154150201397922,
          0.5067193679658791
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 3",
         "type": "scatter",
         "uid": "0b216ed9-0130-4d9d-837c-77b49dbb95d4",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.49249011895402145,
          0.5098814229484603,
          0.5019762849148083,
          0.505928854131887,
          0.5059288537784998,
          0.4996047434599503,
          0.5035573126299108,
          0.4996047434599503,
          0.5003952572468241,
          0.4893280636180531,
          0.5035573126299108,
          0.49802371543857893,
          0.513043478637816,
          0.5019762846085394,
          0.5106719371358397,
          0.5114624509227135,
          0.5122529648038239,
          0.515415019786405,
          0.5154150201397922,
          0.522529644645721,
          0.505138340297895,
          0.5169960478077764,
          0.5201581031437448,
          0.5106719371358397,
          0.4996047434599503,
          0.5169960478077764,
          0.5067193676124919,
          0.5146245063058001,
          0.5043478264639029,
          0.5043478261105157,
          0.5106719367824524
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 4",
         "type": "scatter",
         "uid": "2f9230fa-3bf5-47ea-b643-5e2650adb502",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.505138340297895,
          0.505928854131887,
          0.4948616604559978,
          0.5051383399445077,
          0.498814229272571,
          0.5122529647567056,
          0.49723320195797405,
          0.5146245063058001,
          0.505928854131887,
          0.4940711466220057,
          0.5106719368295707,
          0.5106719367824524,
          0.5027667987959187,
          0.5059288537784998,
          0.5083003956338633,
          0.5098814233018476,
          0.5138339921184208,
          0.5027667987959187,
          0.5146245059995312,
          0.5059288540847687,
          0.5130434783315471,
          0.5169960478077764,
          0.5114624509698318,
          0.505928854131887,
          0.505928854131887,
          0.5098814233018476,
          0.5114624509698318,
          0.5059288537784998,
          0.5130434783315471,
          0.49723320195797405,
          0.5114624509698318
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Test set accuracy of padded BERT dataset with variable maximum lengths"
        }
       }
      },
      "text/html": [
       "<div id=\"6142f664-ca53-4b83-9386-37ca9a91d9a5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {\n",
       "    Plotly.newPlot(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.513043478637816, 0.5122529648038239, 0.5075098817998712, 0.5083003953747127, 0.49407114631573673, 0.5098814233018476, 0.507509881752753, 0.5035573126299108, 0.4996047434599503, 0.5027667987488004, 0.507509881752753, 0.5090909091144682, 0.5067193679187609, 0.5114624509227135, 0.5098814233018476, 0.5162055336203971, 0.5193675893097527, 0.5193675893097527, 0.5233201584797131, 0.5217391304583417, 0.5106719371358397, 0.5106719367824524, 0.5177865616417685, 0.5075098817998712, 0.513043478637816, 0.5043478264639029, 0.5162055336203971, 0.5075098817998712, 0.5114624509698318, 0.513833992471808, 0.5075098817998712], \"type\": \"scatter\", \"uid\": \"36b39775-a328-4c54-a3ca-4455c6dc01d6\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5098814233018476, 0.5098814229484603, 0.49723320160458684, 0.5090909091144682, 0.5051383399445077, 0.505928854131887, 0.498814229272571, 0.5114624509698318, 0.4940711466220057, 0.49169960512002936, 0.4996047431065631, 0.5027667984425315, 0.4956521739366026, 0.5067193679658791, 0.5067193676124919, 0.5043478264167846, 0.5146245063058001, 0.5256916999816894, 0.5201581031437448, 0.515415019786405, 0.5169960478077764, 0.521739130811729, 0.5185770751223734, 0.5154150201397922, 0.5209486169777369, 0.5027667987959187, 0.5011857711279345, 0.5154150201397922, 0.5083003956338633, 0.5075098817998712, 0.5185770754286423], \"type\": \"scatter\", \"uid\": \"05ff3bde-811d-43d5-8421-2f3acd734853\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5035573122765236, 0.5027667984425315, 0.5090909094207372, 0.49090909128603727, 0.5098814233018476, 0.505928854131887, 0.5075098817998712, 0.5035573123236419, 0.5003952572468241, 0.488537549784061, 0.5075098817998712, 0.5035573122765236, 0.5003952572468241, 0.5122529648038239, 0.5051383402507766, 0.5177865616417685, 0.5106719371358397, 0.5019762849619266, 0.5106719368295707, 0.5083003956338633, 0.5146245063058001, 0.5146245063058001, 0.5177865616417685, 0.5067193676596102, 0.5098814233018476, 0.5146245063058001, 0.5138339921184208, 0.5043478264639029, 0.507509881446484, 0.5154150201397922, 0.5067193679658791], \"type\": \"scatter\", \"uid\": \"332e414a-c977-4eeb-894a-69644b06f03d\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.49249011895402145, 0.5098814229484603, 0.5019762849148083, 0.505928854131887, 0.5059288537784998, 0.4996047434599503, 0.5035573126299108, 0.4996047434599503, 0.5003952572468241, 0.4893280636180531, 0.5035573126299108, 0.49802371543857893, 0.513043478637816, 0.5019762846085394, 0.5106719371358397, 0.5114624509227135, 0.5122529648038239, 0.515415019786405, 0.5154150201397922, 0.522529644645721, 0.505138340297895, 0.5169960478077764, 0.5201581031437448, 0.5106719371358397, 0.4996047434599503, 0.5169960478077764, 0.5067193676124919, 0.5146245063058001, 0.5043478264639029, 0.5043478261105157, 0.5106719367824524], \"type\": \"scatter\", \"uid\": \"0b216ed9-0130-4d9d-837c-77b49dbb95d4\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 4\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505138340297895, 0.505928854131887, 0.4948616604559978, 0.5051383399445077, 0.498814229272571, 0.5122529647567056, 0.49723320195797405, 0.5146245063058001, 0.505928854131887, 0.4940711466220057, 0.5106719368295707, 0.5106719367824524, 0.5027667987959187, 0.5059288537784998, 0.5083003956338633, 0.5098814233018476, 0.5138339921184208, 0.5027667987959187, 0.5146245059995312, 0.5059288540847687, 0.5130434783315471, 0.5169960478077764, 0.5114624509698318, 0.505928854131887, 0.505928854131887, 0.5098814233018476, 0.5114624509698318, 0.5059288537784998, 0.5130434783315471, 0.49723320195797405, 0.5114624509698318], \"type\": \"scatter\", \"uid\": \"2f9230fa-3bf5-47ea-b643-5e2650adb502\"}], {\"title\": {\"text\": \"Test set accuracy of padded BERT dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {window._Plotly.Plots.resize(document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"6142f664-ca53-4b83-9386-37ca9a91d9a5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {\n",
       "    Plotly.newPlot(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.513043478637816, 0.5122529648038239, 0.5075098817998712, 0.5083003953747127, 0.49407114631573673, 0.5098814233018476, 0.507509881752753, 0.5035573126299108, 0.4996047434599503, 0.5027667987488004, 0.507509881752753, 0.5090909091144682, 0.5067193679187609, 0.5114624509227135, 0.5098814233018476, 0.5162055336203971, 0.5193675893097527, 0.5193675893097527, 0.5233201584797131, 0.5217391304583417, 0.5106719371358397, 0.5106719367824524, 0.5177865616417685, 0.5075098817998712, 0.513043478637816, 0.5043478264639029, 0.5162055336203971, 0.5075098817998712, 0.5114624509698318, 0.513833992471808, 0.5075098817998712], \"type\": \"scatter\", \"uid\": \"36b39775-a328-4c54-a3ca-4455c6dc01d6\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5098814233018476, 0.5098814229484603, 0.49723320160458684, 0.5090909091144682, 0.5051383399445077, 0.505928854131887, 0.498814229272571, 0.5114624509698318, 0.4940711466220057, 0.49169960512002936, 0.4996047431065631, 0.5027667984425315, 0.4956521739366026, 0.5067193679658791, 0.5067193676124919, 0.5043478264167846, 0.5146245063058001, 0.5256916999816894, 0.5201581031437448, 0.515415019786405, 0.5169960478077764, 0.521739130811729, 0.5185770751223734, 0.5154150201397922, 0.5209486169777369, 0.5027667987959187, 0.5011857711279345, 0.5154150201397922, 0.5083003956338633, 0.5075098817998712, 0.5185770754286423], \"type\": \"scatter\", \"uid\": \"05ff3bde-811d-43d5-8421-2f3acd734853\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5035573122765236, 0.5027667984425315, 0.5090909094207372, 0.49090909128603727, 0.5098814233018476, 0.505928854131887, 0.5075098817998712, 0.5035573123236419, 0.5003952572468241, 0.488537549784061, 0.5075098817998712, 0.5035573122765236, 0.5003952572468241, 0.5122529648038239, 0.5051383402507766, 0.5177865616417685, 0.5106719371358397, 0.5019762849619266, 0.5106719368295707, 0.5083003956338633, 0.5146245063058001, 0.5146245063058001, 0.5177865616417685, 0.5067193676596102, 0.5098814233018476, 0.5146245063058001, 0.5138339921184208, 0.5043478264639029, 0.507509881446484, 0.5154150201397922, 0.5067193679658791], \"type\": \"scatter\", \"uid\": \"332e414a-c977-4eeb-894a-69644b06f03d\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.49249011895402145, 0.5098814229484603, 0.5019762849148083, 0.505928854131887, 0.5059288537784998, 0.4996047434599503, 0.5035573126299108, 0.4996047434599503, 0.5003952572468241, 0.4893280636180531, 0.5035573126299108, 0.49802371543857893, 0.513043478637816, 0.5019762846085394, 0.5106719371358397, 0.5114624509227135, 0.5122529648038239, 0.515415019786405, 0.5154150201397922, 0.522529644645721, 0.505138340297895, 0.5169960478077764, 0.5201581031437448, 0.5106719371358397, 0.4996047434599503, 0.5169960478077764, 0.5067193676124919, 0.5146245063058001, 0.5043478264639029, 0.5043478261105157, 0.5106719367824524], \"type\": \"scatter\", \"uid\": \"0b216ed9-0130-4d9d-837c-77b49dbb95d4\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 4\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505138340297895, 0.505928854131887, 0.4948616604559978, 0.5051383399445077, 0.498814229272571, 0.5122529647567056, 0.49723320195797405, 0.5146245063058001, 0.505928854131887, 0.4940711466220057, 0.5106719368295707, 0.5106719367824524, 0.5027667987959187, 0.5059288537784998, 0.5083003956338633, 0.5098814233018476, 0.5138339921184208, 0.5027667987959187, 0.5146245059995312, 0.5059288540847687, 0.5130434783315471, 0.5169960478077764, 0.5114624509698318, 0.505928854131887, 0.505928854131887, 0.5098814233018476, 0.5114624509698318, 0.5059288537784998, 0.5130434783315471, 0.49723320195797405, 0.5114624509698318], \"type\": \"scatter\", \"uid\": \"2f9230fa-3bf5-47ea-b643-5e2650adb502\"}], {\"title\": {\"text\": \"Test set accuracy of padded BERT dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {window._Plotly.Plots.resize(document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traces = [round1, round2, round3, round4, round5]\n",
    "\n",
    "# Create traces\n",
    "bert_trace = go.Scatter(\n",
    "    x = list(round1.keys()),\n",
    "    y = list(round1.values()),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'BERT'\n",
    ")\n",
    "\n",
    "def create_scatter(counter):\n",
    "    acc_dict = traces[counter]\n",
    "    \n",
    "    return go.Scatter(\n",
    "        x = list(acc_dict.keys()),\n",
    "        y = list(acc_dict.values()),\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Round ' + str(counter)\n",
    "    )\n",
    "\n",
    "trace_data = [create_scatter(trace) for trace in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Test set accuracy of padded BERT dataset with variable maximum lengths',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = trace_data, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "fill": "tozerox",
         "fillcolor": "rgba(0,100,80,0.2)",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "name": "BERT",
         "showlegend": false,
         "type": "scatter",
         "uid": "b54d9309-9b39-4ad6-aef9-1bd4691608bb",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          35,
          34,
          33,
          32,
          31,
          30,
          29,
          28,
          27,
          26,
          25,
          24,
          23,
          22,
          21,
          20,
          19,
          18,
          17,
          16,
          15,
          14,
          13,
          12,
          11,
          10,
          9,
          8,
          7,
          6,
          5
         ],
         "y": [
          0.513043478637816,
          0.5122529648038239,
          0.5090909094207372,
          0.5090909091144682,
          0.5098814233018476,
          0.5122529647567056,
          0.5075098817998712,
          0.5146245063058001,
          0.505928854131887,
          0.5027667987488004,
          0.5106719368295707,
          0.5106719367824524,
          0.513043478637816,
          0.5122529648038239,
          0.5106719371358397,
          0.5177865616417685,
          0.5193675893097527,
          0.5256916999816894,
          0.5233201584797131,
          0.522529644645721,
          0.5169960478077764,
          0.521739130811729,
          0.5201581031437448,
          0.5154150201397922,
          0.5209486169777369,
          0.5169960478077764,
          0.5162055336203971,
          0.5154150201397922,
          0.5130434783315471,
          0.5154150201397922,
          0.5185770754286423,
          0.5067193679658791,
          0.49723320195797405,
          0.5043478264639029,
          0.5043478264639029,
          0.5011857711279345,
          0.5027667987959187,
          0.4996047434599503,
          0.505928854131887,
          0.5114624509698318,
          0.5106719367824524,
          0.505138340297895,
          0.5059288540847687,
          0.5106719368295707,
          0.5019762849619266,
          0.5106719371358397,
          0.5043478264167846,
          0.5051383402507766,
          0.5019762846085394,
          0.4956521739366026,
          0.49802371543857893,
          0.4996047431065631,
          0.488537549784061,
          0.4940711466220057,
          0.4996047434599503,
          0.49723320195797405,
          0.4996047434599503,
          0.49407114631573673,
          0.49090909128603727,
          0.4948616604559978,
          0.5027667984425315,
          0.49249011895402145
         ]
        },
        {
         "line": {
          "color": "rgb(0,100,80)"
         },
         "mode": "lines+markers",
         "name": "BERT",
         "type": "scatter",
         "uid": "d1d2e36a-08d5-4567-b202-7c008f8d60a8",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5048221346936207,
          0.5081422926550326,
          0.5021343876392003,
          0.5038735179703225,
          0.5027667985226326,
          0.5067193679564556,
          0.502924901482616,
          0.5065612651378271,
          0.5000790517414982,
          0.4932806327785899,
          0.5057707512237337,
          0.504822134410911,
          0.5037154153071844,
          0.5076679844158911,
          0.5081422927869638,
          0.5119367591807024,
          0.5141501979347274,
          0.5130434785671384,
          0.5168379449184705,
          0.51478260892182,
          0.5120948619757717,
          0.5162055339031069,
          0.5171541505038973,
          0.5092490121734,
          0.5098814233018476,
          0.5097233205350491,
          0.5098814230898153,
          0.5095652176975732,
          0.5089328065691258,
          0.5076679844959922,
          0.5109881425893354
         ]
        }
       ],
       "layout": {
        "paper_bgcolor": "rgb(255,255,255)",
        "plot_bgcolor": "rgb(229,229,229)",
        "title": {
         "text": "Test set accuracy of padded datasets with variable maximum lengths"
        },
        "xaxis": {
         "gridcolor": "rgb(255,255,255)",
         "range": [
          5,
          35
         ],
         "showgrid": true,
         "showline": false,
         "showticklabels": true,
         "tickcolor": "rgb(127,127,127)",
         "ticks": "outside",
         "zeroline": false
        },
        "yaxis": {
         "gridcolor": "rgb(255,255,255)",
         "showgrid": true,
         "showline": false,
         "showticklabels": true,
         "tickcolor": "rgb(127,127,127)",
         "ticks": "outside",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"2d929b8d-9345-431d-9799-4a5901a917f2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\")) {\n",
       "    Plotly.newPlot(\"2d929b8d-9345-431d-9799-4a5901a917f2\", [{\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,100,80,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"BERT\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.513043478637816, 0.5122529648038239, 0.5090909094207372, 0.5090909091144682, 0.5098814233018476, 0.5122529647567056, 0.5075098817998712, 0.5146245063058001, 0.505928854131887, 0.5027667987488004, 0.5106719368295707, 0.5106719367824524, 0.513043478637816, 0.5122529648038239, 0.5106719371358397, 0.5177865616417685, 0.5193675893097527, 0.5256916999816894, 0.5233201584797131, 0.522529644645721, 0.5169960478077764, 0.521739130811729, 0.5201581031437448, 0.5154150201397922, 0.5209486169777369, 0.5169960478077764, 0.5162055336203971, 0.5154150201397922, 0.5130434783315471, 0.5154150201397922, 0.5185770754286423, 0.5067193679658791, 0.49723320195797405, 0.5043478264639029, 0.5043478264639029, 0.5011857711279345, 0.5027667987959187, 0.4996047434599503, 0.505928854131887, 0.5114624509698318, 0.5106719367824524, 0.505138340297895, 0.5059288540847687, 0.5106719368295707, 0.5019762849619266, 0.5106719371358397, 0.5043478264167846, 0.5051383402507766, 0.5019762846085394, 0.4956521739366026, 0.49802371543857893, 0.4996047431065631, 0.488537549784061, 0.4940711466220057, 0.4996047434599503, 0.49723320195797405, 0.4996047434599503, 0.49407114631573673, 0.49090909128603727, 0.4948616604559978, 0.5027667984425315, 0.49249011895402145], \"type\": \"scatter\", \"uid\": \"b54d9309-9b39-4ad6-aef9-1bd4691608bb\"}, {\"line\": {\"color\": \"rgb(0,100,80)\"}, \"mode\": \"lines+markers\", \"name\": \"BERT\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5048221346936207, 0.5081422926550326, 0.5021343876392003, 0.5038735179703225, 0.5027667985226326, 0.5067193679564556, 0.502924901482616, 0.5065612651378271, 0.5000790517414982, 0.4932806327785899, 0.5057707512237337, 0.504822134410911, 0.5037154153071844, 0.5076679844158911, 0.5081422927869638, 0.5119367591807024, 0.5141501979347274, 0.5130434785671384, 0.5168379449184705, 0.51478260892182, 0.5120948619757717, 0.5162055339031069, 0.5171541505038973, 0.5092490121734, 0.5098814233018476, 0.5097233205350491, 0.5098814230898153, 0.5095652176975732, 0.5089328065691258, 0.5076679844959922, 0.5109881425893354], \"type\": \"scatter\", \"uid\": \"d1d2e36a-08d5-4567-b202-7c008f8d60a8\"}], {\"paper_bgcolor\": \"rgb(255,255,255)\", \"plot_bgcolor\": \"rgb(229,229,229)\", \"title\": {\"text\": \"Test set accuracy of padded datasets with variable maximum lengths\"}, \"xaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"range\": [5, 35], \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}, \"yaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\")) {window._Plotly.Plots.resize(document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2d929b8d-9345-431d-9799-4a5901a917f2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\")) {\n",
       "    Plotly.newPlot(\"2d929b8d-9345-431d-9799-4a5901a917f2\", [{\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,100,80,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"BERT\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.513043478637816, 0.5122529648038239, 0.5090909094207372, 0.5090909091144682, 0.5098814233018476, 0.5122529647567056, 0.5075098817998712, 0.5146245063058001, 0.505928854131887, 0.5027667987488004, 0.5106719368295707, 0.5106719367824524, 0.513043478637816, 0.5122529648038239, 0.5106719371358397, 0.5177865616417685, 0.5193675893097527, 0.5256916999816894, 0.5233201584797131, 0.522529644645721, 0.5169960478077764, 0.521739130811729, 0.5201581031437448, 0.5154150201397922, 0.5209486169777369, 0.5169960478077764, 0.5162055336203971, 0.5154150201397922, 0.5130434783315471, 0.5154150201397922, 0.5185770754286423, 0.5067193679658791, 0.49723320195797405, 0.5043478264639029, 0.5043478264639029, 0.5011857711279345, 0.5027667987959187, 0.4996047434599503, 0.505928854131887, 0.5114624509698318, 0.5106719367824524, 0.505138340297895, 0.5059288540847687, 0.5106719368295707, 0.5019762849619266, 0.5106719371358397, 0.5043478264167846, 0.5051383402507766, 0.5019762846085394, 0.4956521739366026, 0.49802371543857893, 0.4996047431065631, 0.488537549784061, 0.4940711466220057, 0.4996047434599503, 0.49723320195797405, 0.4996047434599503, 0.49407114631573673, 0.49090909128603727, 0.4948616604559978, 0.5027667984425315, 0.49249011895402145], \"type\": \"scatter\", \"uid\": \"b54d9309-9b39-4ad6-aef9-1bd4691608bb\"}, {\"line\": {\"color\": \"rgb(0,100,80)\"}, \"mode\": \"lines+markers\", \"name\": \"BERT\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5048221346936207, 0.5081422926550326, 0.5021343876392003, 0.5038735179703225, 0.5027667985226326, 0.5067193679564556, 0.502924901482616, 0.5065612651378271, 0.5000790517414982, 0.4932806327785899, 0.5057707512237337, 0.504822134410911, 0.5037154153071844, 0.5076679844158911, 0.5081422927869638, 0.5119367591807024, 0.5141501979347274, 0.5130434785671384, 0.5168379449184705, 0.51478260892182, 0.5120948619757717, 0.5162055339031069, 0.5171541505038973, 0.5092490121734, 0.5098814233018476, 0.5097233205350491, 0.5098814230898153, 0.5095652176975732, 0.5089328065691258, 0.5076679844959922, 0.5109881425893354], \"type\": \"scatter\", \"uid\": \"d1d2e36a-08d5-4567-b202-7c008f8d60a8\"}], {\"paper_bgcolor\": \"rgb(255,255,255)\", \"plot_bgcolor\": \"rgb(229,229,229)\", \"title\": {\"text\": \"Test set accuracy of padded datasets with variable maximum lengths\"}, \"xaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"range\": [5, 35], \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}, \"yaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\")) {window._Plotly.Plots.resize(document.getElementById(\"2d929b8d-9345-431d-9799-4a5901a917f2\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_matrix = np.transpose(np.array([np.array(list(acc_round.values())) for acc_round in [round1, round2, round3, round4, round5]]))\n",
    "\n",
    "x = list(range(5, 36))\n",
    "x_rev = x[::-1]\n",
    "\n",
    "# BERT\n",
    "bert_y = [np.average(row) for row in bert_matrix]\n",
    "bert_y_upper = [row.max() for row in bert_matrix]\n",
    "bert_y_lower = [row.min() for row in bert_matrix]\n",
    "bert_y_lower = bert_y_lower[::-1]\n",
    "\n",
    "bert1 = go.Scatter(\n",
    "    x = x + x_rev,\n",
    "    y = bert_y_upper + bert_y_lower,\n",
    "    fill = 'tozerox',\n",
    "    fillcolor = 'rgba(0,100,80,0.2)',\n",
    "    line = dict(color = 'rgba(255,255,255,0)'),\n",
    "    showlegend = False,\n",
    "    name = 'BERT',\n",
    ")\n",
    "bert2 = go.Scatter(\n",
    "    x = x,\n",
    "    y = bert_y,\n",
    "    line = dict(color='rgb(0,100,80)'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'BERT',\n",
    ")\n",
    "\n",
    "data = [bert1, bert2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Test set accuracy of padded datasets with variable maximum lengths',\n",
    "    paper_bgcolor = 'rgb(255,255,255)',\n",
    "    plot_bgcolor = 'rgb(229,229,229)',\n",
    "    xaxis = dict(\n",
    "        gridcolor = 'rgb(255,255,255)',\n",
    "        range = [5,35],\n",
    "        showgrid = True,\n",
    "        showline = False,\n",
    "        showticklabels = True,\n",
    "        tickcolor = 'rgb(127,127,127)',\n",
    "        ticks = 'outside',\n",
    "        zeroline = False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        gridcolor='rgb(255,255,255)',\n",
    "        showgrid = True,\n",
    "        showline = False,\n",
    "        showticklabels = True,\n",
    "        tickcolor = 'rgb(127,127,127)',\n",
    "        ticks = 'outside',\n",
    "        zeroline = False\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_score(X_train, X_test, X_validation, y_train = general['train']['label'], y_test = general['test']['label'], y_validation = general['validation']['label']):\n",
    "    # Rearrange data types    \n",
    "    params = locals().copy()    \n",
    "    inputs = {\n",
    "        dataset: np.array(params[dataset])\n",
    "        for dataset in params.keys()\n",
    "    }\n",
    "    \n",
    "    # Reshape datasets\n",
    "    for dataset in inputs.keys():\n",
    "        if dataset[0:1] == 'X':\n",
    "            inputs[dataset] = np.reshape(inputs[dataset], (inputs[dataset].shape[0], inputs[dataset].shape[1], 1))\n",
    "        elif dataset[0:1] == 'y':\n",
    "            inputs[dataset] = np_utils.to_categorical(np.array(inputs[dataset]), 3)\n",
    "    \n",
    "    # Set model parameters\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    input_shape =  inputs['X_train'].shape\n",
    "    print(inputs['X_train'].shape)\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape = input_shape))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile('sgd', 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    \n",
    "    # Fit the training set over the model and correct on the validation set\n",
    "    model.fit(inputs['X_train'], inputs['y_train'],\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            validation_data = (inputs['X_validation'], inputs['y_validation']))\n",
    "    \n",
    "    # Get score over the test set\n",
    "    score, acc = model.evaluate(inputs['X_test'], inputs['y_test'])\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cnn_score(max_pooled_bert['train'], max_pooled_bert['test'], max_pooled_bert['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### References\n",
    "\n",
    "```\n",
    "@article{DBLP:journals/corr/Wang17j,\n",
    "  author    = {William Yang Wang},\n",
    "  title     = {\"Liar, Liar Pants on Fire\": {A} New Benchmark Dataset for Fake News\n",
    "               Detection},\n",
    "  journal   = {CoRR},\n",
    "  volume    = {abs/1705.00648},\n",
    "  year      = {2017},\n",
    "  url       = {http://arxiv.org/abs/1705.00648},\n",
    "  archivePrefix = {arXiv},\n",
    "  eprint    = {1705.00648},\n",
    "  timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},\n",
    "  biburl    = {https://dblp.org/rec/bib/journals/corr/Wang17j},\n",
    "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
