{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural classification\n",
    "As has been proven by [Wang (2017)](https://arxiv.org/abs/1705.00648), neural classifiers carry better results than non-neural classifiers when detecting fake news. However, it is unknown how well neural networks classify fake news when using previously mentioned text embeddings. \n",
    "In this notebook, the second research question will be answered: *how well do neural network architecture classify fake news compared to non-neural classification algorithms?*\n",
    "\n",
    "<hr>\n",
    "\n",
    "## On the usage of neural networks\n",
    "Literature on CNNs and Bi-LSTMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Reshape, Conv1D, Flatten\n",
    "\n",
    "# Set offline mode for plotly\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "# The DataLoader class gives access to pretrained vectors from the Liar dataset\n",
    "from data_loader import DataLoader\n",
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = data.get_dfs()\n",
    "\n",
    "# Recode labels from 6 to 3\n",
    "def recode(label):\n",
    "    if label == 'false' or label == 'pants-fire' or label == 'barely-true':\n",
    "        return 0\n",
    "    elif label == 'true' or label == 'mostly-true':\n",
    "        return 2\n",
    "    elif label == 'half-true':\n",
    "        return 1\n",
    "\n",
    "for dataset in general.keys():\n",
    "    general[dataset]['label'] = general[dataset]['label'].apply(lambda label: recode(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Bidirectional LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = data.get_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max-pooled BERT embeddings from RQ1\n",
    "def max_pool(statement):\n",
    "    if len(statement) > 1:\n",
    "        return [row.max() for row in np.transpose([[token_row.max() for token_row in np.transpose(np.array(sentence))] for sentence in statement])]\n",
    "    else:\n",
    "        return [token_row.max() for token_row in np.transpose(statement[0])]\n",
    "\n",
    "max_pooled_bert = {\n",
    "    dataset: pd.DataFrame(list(bert[dataset].statement.apply(lambda statement: max_pool(statement)).values))\n",
    "    for dataset in bert.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_score(X_train, X_test, X_validation, y_train = general['train']['label'], y_test = general['test']['label'], y_validation = general['validation']['label'], reshape = True):\n",
    "    # Rearrange data types    \n",
    "    params = locals().copy()    \n",
    "    inputs = {\n",
    "        dataset: np.array(params[dataset])\n",
    "        for dataset in params.keys()\n",
    "    }\n",
    "    \n",
    "    for dataset in inputs.keys():\n",
    "        if dataset[0:1] == 'X' and reshape:\n",
    "            # Reshape datasets from 2D to 3D\n",
    "            inputs[dataset] = np.reshape(inputs[dataset], (inputs[dataset].shape[0], inputs[dataset].shape[1], 1))\n",
    "        elif dataset[0:1] == 'y':\n",
    "            inputs[dataset] = np_utils.to_categorical(np.array(inputs[dataset]), 3)\n",
    "    \n",
    "    # Set model parameters\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    input_shape = X_train.shape\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, input_shape = input_shape)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile('sgd', 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    \n",
    "    # Fit the training set over the model and correct on the validation set\n",
    "    model.fit(inputs['X_train'], inputs['y_train'],\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            validation_data = (inputs['X_validation'], inputs['y_validation']))\n",
    "    \n",
    "    # Get score over the test set\n",
    "    score, acc = model.evaluate(inputs['X_test'], inputs['y_test'])\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-05-21 12:40:37,047 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-05-21 12:40:37,448 From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2019-05-21 12:40:37,537 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 829s 81ms/step - loss: 1.0743 - acc: 0.4087 - val_loss: 1.0423 - val_acc: 0.4798\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 844s 82ms/step - loss: 1.0632 - acc: 0.4300 - val_loss: 1.0392 - val_acc: 0.4798\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 838s 82ms/step - loss: 1.0590 - acc: 0.4354 - val_loss: 1.0408 - val_acc: 0.4798\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 840s 82ms/step - loss: 1.0592 - acc: 0.4354 - val_loss: 1.0432 - val_acc: 0.4798\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 809s 79ms/step - loss: 1.0591 - acc: 0.4337 - val_loss: 1.0395 - val_acc: 0.4798\n",
      "1265/1265 [==============================] - 16s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43715415052745654"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bilstm_score(max_pooled_bert['train'], max_pooled_bert['test'], max_pooled_bert['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the condensed datasets from RQ1 do not perform well when using a neural classifier. The next step is trying out a padding approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 69s 7ms/step - loss: 1.1184 - acc: 0.4145 - val_loss: 1.0170 - val_acc: 0.5093\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0597 - acc: 0.4532 - val_loss: 1.0196 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0432 - acc: 0.4707 - val_loss: 1.0158 - val_acc: 0.5125\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0362 - acc: 0.4775 - val_loss: 1.0134 - val_acc: 0.5117\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 16s 2ms/step - loss: 1.0279 - acc: 0.4821 - val_loss: 1.0089 - val_acc: 0.5164\n",
      "1265/1265 [==============================] - 2s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 46s 4ms/step - loss: 1.1094 - acc: 0.4181 - val_loss: 1.0184 - val_acc: 0.4907\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0558 - acc: 0.4556 - val_loss: 1.0125 - val_acc: 0.5125\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0428 - acc: 0.4693 - val_loss: 1.0125 - val_acc: 0.5070\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0332 - acc: 0.4863 - val_loss: 1.0140 - val_acc: 0.5008\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0303 - acc: 0.4824 - val_loss: 1.0051 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 1s 594us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.1187 - acc: 0.4151 - val_loss: 1.0248 - val_acc: 0.5109\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0541 - acc: 0.4529 - val_loss: 1.0166 - val_acc: 0.5125\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0422 - acc: 0.4718 - val_loss: 1.0122 - val_acc: 0.5078\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0347 - acc: 0.4808 - val_loss: 1.0118 - val_acc: 0.5047\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 19s 2ms/step - loss: 1.0292 - acc: 0.4889 - val_loss: 1.0056 - val_acc: 0.5109\n",
      "1265/1265 [==============================] - 1s 969us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.1133 - acc: 0.4260 - val_loss: 1.0178 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0581 - acc: 0.4538 - val_loss: 1.0119 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0404 - acc: 0.4719 - val_loss: 1.0130 - val_acc: 0.5039\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0340 - acc: 0.4828 - val_loss: 1.0065 - val_acc: 0.5055\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 21s 2ms/step - loss: 1.0276 - acc: 0.4863 - val_loss: 1.0027 - val_acc: 0.5125\n",
      "1265/1265 [==============================] - 1s 799us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.1089 - acc: 0.4181 - val_loss: 1.0162 - val_acc: 0.5031\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0551 - acc: 0.4594 - val_loss: 1.0202 - val_acc: 0.5047\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0381 - acc: 0.4771 - val_loss: 1.0091 - val_acc: 0.5078\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0320 - acc: 0.4829 - val_loss: 1.0067 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0247 - acc: 0.4908 - val_loss: 1.0029 - val_acc: 0.5016\n",
      "1265/1265 [==============================] - 1s 846us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.1186 - acc: 0.4209 - val_loss: 1.0138 - val_acc: 0.5062\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0519 - acc: 0.4614 - val_loss: 1.0098 - val_acc: 0.5008\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 24s 2ms/step - loss: 1.0398 - acc: 0.4782 - val_loss: 1.0044 - val_acc: 0.5062\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0280 - acc: 0.4896 - val_loss: 1.0080 - val_acc: 0.5101\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.0241 - acc: 0.4943 - val_loss: 1.0050 - val_acc: 0.5125\n",
      "1265/1265 [==============================] - 1s 929us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.1218 - acc: 0.4208 - val_loss: 1.0134 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0544 - acc: 0.4600 - val_loss: 1.0069 - val_acc: 0.5202\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0398 - acc: 0.4773 - val_loss: 1.0043 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0296 - acc: 0.4862 - val_loss: 1.0027 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0265 - acc: 0.4872 - val_loss: 0.9985 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 1s 1ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.1138 - acc: 0.4279 - val_loss: 1.0142 - val_acc: 0.5109\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0477 - acc: 0.4682 - val_loss: 1.0073 - val_acc: 0.5164\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0368 - acc: 0.4805 - val_loss: 1.0111 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0281 - acc: 0.4867 - val_loss: 1.0011 - val_acc: 0.5218\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0280 - acc: 0.4947 - val_loss: 1.0041 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 3s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 80s 8ms/step - loss: 1.1205 - acc: 0.4236 - val_loss: 1.0263 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0541 - acc: 0.4649 - val_loss: 1.0081 - val_acc: 0.5187\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0391 - acc: 0.4769 - val_loss: 1.0083 - val_acc: 0.5218\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0296 - acc: 0.4863 - val_loss: 1.0060 - val_acc: 0.5047\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0239 - acc: 0.4927 - val_loss: 1.0026 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 3s 2ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 86s 8ms/step - loss: 1.1171 - acc: 0.4152 - val_loss: 1.0107 - val_acc: 0.5078\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0496 - acc: 0.4637 - val_loss: 1.0054 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0413 - acc: 0.4780 - val_loss: 1.0082 - val_acc: 0.5179\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0297 - acc: 0.4904 - val_loss: 1.0004 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0234 - acc: 0.4949 - val_loss: 0.9993 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 3s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 92s 9ms/step - loss: 1.1165 - acc: 0.4206 - val_loss: 1.0214 - val_acc: 0.5148\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0553 - acc: 0.4656 - val_loss: 1.0178 - val_acc: 0.5109\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0350 - acc: 0.4852 - val_loss: 1.0104 - val_acc: 0.5101\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0312 - acc: 0.4890 - val_loss: 1.0051 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0229 - acc: 0.4910 - val_loss: 1.0055 - val_acc: 0.5101\n",
      "1265/1265 [==============================] - 3s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 91s 9ms/step - loss: 1.1168 - acc: 0.4210 - val_loss: 1.0127 - val_acc: 0.5047\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 37s 4ms/step - loss: 1.0508 - acc: 0.4668 - val_loss: 1.0166 - val_acc: 0.5086\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0364 - acc: 0.4793 - val_loss: 1.0032 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 32s 3ms/step - loss: 1.0281 - acc: 0.4893 - val_loss: 1.0000 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0228 - acc: 0.4973 - val_loss: 1.0013 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 98s 10ms/step - loss: 1.1218 - acc: 0.4131 - val_loss: 1.0302 - val_acc: 0.4984\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0546 - acc: 0.4616 - val_loss: 1.0226 - val_acc: 0.5008\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 36s 4ms/step - loss: 1.0387 - acc: 0.4726 - val_loss: 1.0115 - val_acc: 0.5164\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0314 - acc: 0.4861 - val_loss: 1.0049 - val_acc: 0.5164\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.0245 - acc: 0.4940 - val_loss: 1.0055 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 103s 10ms/step - loss: 1.1113 - acc: 0.4235 - val_loss: 1.0184 - val_acc: 0.5234\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0534 - acc: 0.4643 - val_loss: 1.0104 - val_acc: 0.5226\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 36s 3ms/step - loss: 1.0409 - acc: 0.4802 - val_loss: 1.0079 - val_acc: 0.5117\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 36s 4ms/step - loss: 1.0321 - acc: 0.4882 - val_loss: 1.0040 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 37s 4ms/step - loss: 1.0239 - acc: 0.5000 - val_loss: 1.0034 - val_acc: 0.5140\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 101s 10ms/step - loss: 1.1158 - acc: 0.4191 - val_loss: 1.0152 - val_acc: 0.5226\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0550 - acc: 0.4584 - val_loss: 1.0119 - val_acc: 0.5249\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0378 - acc: 0.4787 - val_loss: 1.0057 - val_acc: 0.5296\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0310 - acc: 0.4812 - val_loss: 1.0030 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0227 - acc: 0.4948 - val_loss: 0.9970 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 109s 11ms/step - loss: 1.1228 - acc: 0.4128 - val_loss: 1.0199 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0554 - acc: 0.4577 - val_loss: 1.0189 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0387 - acc: 0.4784 - val_loss: 1.0061 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0341 - acc: 0.4836 - val_loss: 1.0074 - val_acc: 0.5195\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0242 - acc: 0.4958 - val_loss: 1.0025 - val_acc: 0.5140\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 111s 11ms/step - loss: 1.1078 - acc: 0.4219 - val_loss: 1.0287 - val_acc: 0.4984\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0534 - acc: 0.4610 - val_loss: 1.0140 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0422 - acc: 0.4721 - val_loss: 1.0134 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0265 - acc: 0.4914 - val_loss: 1.0109 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0268 - acc: 0.4949 - val_loss: 1.0093 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 118s 12ms/step - loss: 1.1146 - acc: 0.4152 - val_loss: 1.0207 - val_acc: 0.5031\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0577 - acc: 0.4632 - val_loss: 1.0113 - val_acc: 0.5249\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0401 - acc: 0.4759 - val_loss: 1.0133 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 43s 4ms/step - loss: 1.0335 - acc: 0.4819 - val_loss: 1.0071 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 43s 4ms/step - loss: 1.0266 - acc: 0.4901 - val_loss: 1.0044 - val_acc: 0.5234\n",
      "1265/1265 [==============================] - 6s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 110s 11ms/step - loss: 1.1089 - acc: 0.4237 - val_loss: 1.0265 - val_acc: 0.5140\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.0583 - acc: 0.4500 - val_loss: 1.0147 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0430 - acc: 0.4778 - val_loss: 1.0108 - val_acc: 0.5241\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0318 - acc: 0.4808 - val_loss: 1.0067 - val_acc: 0.5226\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0303 - acc: 0.4843 - val_loss: 1.0078 - val_acc: 0.5241\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 114s 11ms/step - loss: 1.1008 - acc: 0.4262 - val_loss: 1.0131 - val_acc: 0.5070\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0570 - acc: 0.4583 - val_loss: 1.0094 - val_acc: 0.5117\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 46s 5ms/step - loss: 1.0434 - acc: 0.4738 - val_loss: 1.0143 - val_acc: 0.5148\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0325 - acc: 0.4833 - val_loss: 1.0063 - val_acc: 0.5187\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0260 - acc: 0.4900 - val_loss: 1.0022 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 120s 12ms/step - loss: 1.1036 - acc: 0.4241 - val_loss: 1.0248 - val_acc: 0.4938\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0551 - acc: 0.4624 - val_loss: 1.0112 - val_acc: 0.5195\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0423 - acc: 0.4752 - val_loss: 1.0161 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0296 - acc: 0.4879 - val_loss: 1.0038 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0270 - acc: 0.4869 - val_loss: 1.0063 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 117s 11ms/step - loss: 1.1012 - acc: 0.4247 - val_loss: 1.0202 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.0566 - acc: 0.4576 - val_loss: 1.0107 - val_acc: 0.5164\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0400 - acc: 0.4775 - val_loss: 1.0086 - val_acc: 0.5218\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0354 - acc: 0.4865 - val_loss: 1.0027 - val_acc: 0.5265\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0266 - acc: 0.4919 - val_loss: 1.0065 - val_acc: 0.5257\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 130s 13ms/step - loss: 1.0999 - acc: 0.4246 - val_loss: 1.0188 - val_acc: 0.4992\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0588 - acc: 0.4596 - val_loss: 1.0145 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0415 - acc: 0.4750 - val_loss: 1.0089 - val_acc: 0.5156\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0319 - acc: 0.4848 - val_loss: 1.0036 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0260 - acc: 0.4872 - val_loss: 1.0034 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 133s 13ms/step - loss: 1.1086 - acc: 0.4064 - val_loss: 1.0186 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 65s 6ms/step - loss: 1.0563 - acc: 0.4585 - val_loss: 1.0152 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0411 - acc: 0.4723 - val_loss: 1.0108 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0383 - acc: 0.4797 - val_loss: 1.0096 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0304 - acc: 0.4826 - val_loss: 1.0036 - val_acc: 0.5148\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 136s 13ms/step - loss: 1.0960 - acc: 0.4262 - val_loss: 1.0261 - val_acc: 0.4774\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 67s 7ms/step - loss: 1.0572 - acc: 0.4566 - val_loss: 1.0126 - val_acc: 0.5202\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0404 - acc: 0.4806 - val_loss: 1.0154 - val_acc: 0.5023\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0341 - acc: 0.4777 - val_loss: 1.0074 - val_acc: 0.5148\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0242 - acc: 0.4919 - val_loss: 1.0010 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 7s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 132s 13ms/step - loss: 1.0877 - acc: 0.4269 - val_loss: 1.0218 - val_acc: 0.5055\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.0545 - acc: 0.4550 - val_loss: 1.0150 - val_acc: 0.5101\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0455 - acc: 0.4722 - val_loss: 1.0101 - val_acc: 0.5101\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0369 - acc: 0.4793 - val_loss: 1.0025 - val_acc: 0.5109\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0328 - acc: 0.4806 - val_loss: 1.0035 - val_acc: 0.5218\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 134s 13ms/step - loss: 1.0966 - acc: 0.4192 - val_loss: 1.0159 - val_acc: 0.5093\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 70s 7ms/step - loss: 1.0535 - acc: 0.4648 - val_loss: 1.0140 - val_acc: 0.5179\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.0407 - acc: 0.4737 - val_loss: 1.0057 - val_acc: 0.5148\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0344 - acc: 0.4890 - val_loss: 1.0030 - val_acc: 0.5234\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0281 - acc: 0.4929 - val_loss: 1.0092 - val_acc: 0.5218\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 141s 14ms/step - loss: 1.0952 - acc: 0.4262 - val_loss: 1.0169 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 73s 7ms/step - loss: 1.0548 - acc: 0.4621 - val_loss: 1.0139 - val_acc: 0.5078\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0452 - acc: 0.4678 - val_loss: 1.0068 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 60s 6ms/step - loss: 1.0353 - acc: 0.4783 - val_loss: 1.0042 - val_acc: 0.5140\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 60s 6ms/step - loss: 1.0292 - acc: 0.4875 - val_loss: 0.9996 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 8s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 138s 14ms/step - loss: 1.0938 - acc: 0.4192 - val_loss: 1.0201 - val_acc: 0.5156\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.0523 - acc: 0.4641 - val_loss: 1.0134 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0419 - acc: 0.4745 - val_loss: 1.0075 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0364 - acc: 0.4815 - val_loss: 1.0043 - val_acc: 0.5218\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0280 - acc: 0.4910 - val_loss: 1.0054 - val_acc: 0.5078\n",
      "1265/1265 [==============================] - 8s 7ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 144s 14ms/step - loss: 1.1040 - acc: 0.4251 - val_loss: 1.0204 - val_acc: 0.4938\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 77s 8ms/step - loss: 1.0522 - acc: 0.4651 - val_loss: 1.0147 - val_acc: 0.5016\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0452 - acc: 0.4717 - val_loss: 1.0112 - val_acc: 0.5117\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0349 - acc: 0.4837 - val_loss: 1.0142 - val_acc: 0.5062\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 63s 6ms/step - loss: 1.0292 - acc: 0.4872 - val_loss: 0.9990 - val_acc: 0.5179\n",
      "1265/1265 [==============================] - 9s 7ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 147s 14ms/step - loss: 1.0870 - acc: 0.4226 - val_loss: 1.0187 - val_acc: 0.5117\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 79s 8ms/step - loss: 1.0529 - acc: 0.4603 - val_loss: 1.0116 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 73s 7ms/step - loss: 1.0456 - acc: 0.4740 - val_loss: 1.0122 - val_acc: 0.5055\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.0368 - acc: 0.4828 - val_loss: 1.0076 - val_acc: 0.5125\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 72s 7ms/step - loss: 1.0324 - acc: 0.4843 - val_loss: 1.0060 - val_acc: 0.5226\n",
      "1265/1265 [==============================] - 8s 6ms/step\n",
      "CPU times: user 8h 57s, sys: 2h 14min 29s, total: 10h 15min 26s\n",
      "Wall time: 2h 44min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Store accuracies\n",
    "accuracies = {\n",
    "    padding_len: 0.0 for padding_len in list(range(5,36))\n",
    "}\n",
    "\n",
    "concatenated_bert = {\n",
    "    dataset: [np.concatenate(np.array(statement)) for statement in bert[dataset].statement]\n",
    "    for dataset in bert.keys()\n",
    "}\n",
    "\n",
    "for max_len in accuracies.keys():\n",
    "    padded_bert = {\n",
    "        dataset: sequence.pad_sequences(concatenated_bert[dataset], maxlen = max_len, dtype = float)\n",
    "        for dataset in concatenated_bert.keys()\n",
    "    }\n",
    "    \n",
    "    accuracies[max_len] = get_bilstm_score(padded_bert['train'], padded_bert['test'], padded_bert['validation'], reshape = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{5: 0.513043478637816,\n",
       "  6: 0.5122529648038239,\n",
       "  7: 0.5075098817998712,\n",
       "  8: 0.5083003953747127,\n",
       "  9: 0.49407114631573673,\n",
       "  10: 0.5098814233018476,\n",
       "  11: 0.507509881752753,\n",
       "  12: 0.5035573126299108,\n",
       "  13: 0.4996047434599503,\n",
       "  14: 0.5027667987488004,\n",
       "  15: 0.507509881752753,\n",
       "  16: 0.5090909091144682,\n",
       "  17: 0.5067193679187609,\n",
       "  18: 0.5114624509227135,\n",
       "  19: 0.5098814233018476,\n",
       "  20: 0.5162055336203971,\n",
       "  21: 0.5193675893097527,\n",
       "  22: 0.5193675893097527,\n",
       "  23: 0.5233201584797131,\n",
       "  24: 0.5217391304583417,\n",
       "  25: 0.5106719371358397,\n",
       "  26: 0.5106719367824524,\n",
       "  27: 0.5177865616417685,\n",
       "  28: 0.5075098817998712,\n",
       "  29: 0.513043478637816,\n",
       "  30: 0.5043478264639029,\n",
       "  31: 0.5162055336203971,\n",
       "  32: 0.5075098817998712,\n",
       "  33: 0.5114624509698318,\n",
       "  34: 0.513833992471808,\n",
       "  35: 0.5075098817998712},\n",
       " {5: 0.5098814233018476,\n",
       "  6: 0.5098814229484603,\n",
       "  7: 0.49723320160458684,\n",
       "  8: 0.5090909091144682,\n",
       "  9: 0.5051383399445077,\n",
       "  10: 0.505928854131887,\n",
       "  11: 0.498814229272571,\n",
       "  12: 0.5114624509698318,\n",
       "  13: 0.4940711466220057,\n",
       "  14: 0.49169960512002936,\n",
       "  15: 0.4996047431065631,\n",
       "  16: 0.5027667984425315,\n",
       "  17: 0.4956521739366026,\n",
       "  18: 0.5067193679658791,\n",
       "  19: 0.5067193676124919,\n",
       "  20: 0.5043478264167846,\n",
       "  21: 0.5146245063058001,\n",
       "  22: 0.5256916999816894,\n",
       "  23: 0.5201581031437448,\n",
       "  24: 0.515415019786405,\n",
       "  25: 0.5169960478077764,\n",
       "  26: 0.521739130811729,\n",
       "  27: 0.5185770751223734,\n",
       "  28: 0.5154150201397922,\n",
       "  29: 0.5209486169777369,\n",
       "  30: 0.5027667987959187,\n",
       "  31: 0.5011857711279345,\n",
       "  32: 0.5154150201397922,\n",
       "  33: 0.5083003956338633,\n",
       "  34: 0.5075098817998712,\n",
       "  35: 0.5185770754286423},\n",
       " {5: 0.5035573122765236,\n",
       "  6: 0.5027667984425315,\n",
       "  7: 0.5090909094207372,\n",
       "  8: 0.49090909128603727,\n",
       "  9: 0.5098814233018476,\n",
       "  10: 0.505928854131887,\n",
       "  11: 0.5075098817998712,\n",
       "  12: 0.5035573123236419,\n",
       "  13: 0.5003952572468241,\n",
       "  14: 0.488537549784061,\n",
       "  15: 0.5075098817998712,\n",
       "  16: 0.5035573122765236,\n",
       "  17: 0.5003952572468241,\n",
       "  18: 0.5122529648038239,\n",
       "  19: 0.5051383402507766,\n",
       "  20: 0.5177865616417685,\n",
       "  21: 0.5106719371358397,\n",
       "  22: 0.5019762849619266,\n",
       "  23: 0.5106719368295707,\n",
       "  24: 0.5083003956338633,\n",
       "  25: 0.5146245063058001,\n",
       "  26: 0.5146245063058001,\n",
       "  27: 0.5177865616417685,\n",
       "  28: 0.5067193676596102,\n",
       "  29: 0.5098814233018476,\n",
       "  30: 0.5146245063058001,\n",
       "  31: 0.5138339921184208,\n",
       "  32: 0.5043478264639029,\n",
       "  33: 0.507509881446484,\n",
       "  34: 0.5154150201397922,\n",
       "  35: 0.5067193679658791},\n",
       " {5: 0.49249011895402145,\n",
       "  6: 0.5098814229484603,\n",
       "  7: 0.5019762849148083,\n",
       "  8: 0.505928854131887,\n",
       "  9: 0.5059288537784998,\n",
       "  10: 0.4996047434599503,\n",
       "  11: 0.5035573126299108,\n",
       "  12: 0.4996047434599503,\n",
       "  13: 0.5003952572468241,\n",
       "  14: 0.4893280636180531,\n",
       "  15: 0.5035573126299108,\n",
       "  16: 0.49802371543857893,\n",
       "  17: 0.513043478637816,\n",
       "  18: 0.5019762846085394,\n",
       "  19: 0.5106719371358397,\n",
       "  20: 0.5114624509227135,\n",
       "  21: 0.5122529648038239,\n",
       "  22: 0.515415019786405,\n",
       "  23: 0.5154150201397922,\n",
       "  24: 0.522529644645721,\n",
       "  25: 0.505138340297895,\n",
       "  26: 0.5169960478077764,\n",
       "  27: 0.5201581031437448,\n",
       "  28: 0.5106719371358397,\n",
       "  29: 0.4996047434599503,\n",
       "  30: 0.5169960478077764,\n",
       "  31: 0.5067193676124919,\n",
       "  32: 0.5146245063058001,\n",
       "  33: 0.5043478264639029,\n",
       "  34: 0.5043478261105157,\n",
       "  35: 0.5106719367824524},\n",
       " {5: 0.505138340297895,\n",
       "  6: 0.505928854131887,\n",
       "  7: 0.4948616604559978,\n",
       "  8: 0.5051383399445077,\n",
       "  9: 0.498814229272571,\n",
       "  10: 0.5122529647567056,\n",
       "  11: 0.49723320195797405,\n",
       "  12: 0.5146245063058001,\n",
       "  13: 0.505928854131887,\n",
       "  14: 0.4940711466220057,\n",
       "  15: 0.5106719368295707,\n",
       "  16: 0.5106719367824524,\n",
       "  17: 0.5027667987959187,\n",
       "  18: 0.5059288537784998,\n",
       "  19: 0.5083003956338633,\n",
       "  20: 0.5098814233018476,\n",
       "  21: 0.5138339921184208,\n",
       "  22: 0.5027667987959187,\n",
       "  23: 0.5146245059995312,\n",
       "  24: 0.5059288540847687,\n",
       "  25: 0.5130434783315471,\n",
       "  26: 0.5169960478077764,\n",
       "  27: 0.5114624509698318,\n",
       "  28: 0.505928854131887,\n",
       "  29: 0.505928854131887,\n",
       "  30: 0.5098814233018476,\n",
       "  31: 0.5114624509698318,\n",
       "  32: 0.5059288537784998,\n",
       "  33: 0.5130434783315471,\n",
       "  34: 0.49723320195797405,\n",
       "  35: 0.5114624509698318}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Round 0",
         "type": "scatter",
         "uid": "36b39775-a328-4c54-a3ca-4455c6dc01d6",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.513043478637816,
          0.5122529648038239,
          0.5075098817998712,
          0.5083003953747127,
          0.49407114631573673,
          0.5098814233018476,
          0.507509881752753,
          0.5035573126299108,
          0.4996047434599503,
          0.5027667987488004,
          0.507509881752753,
          0.5090909091144682,
          0.5067193679187609,
          0.5114624509227135,
          0.5098814233018476,
          0.5162055336203971,
          0.5193675893097527,
          0.5193675893097527,
          0.5233201584797131,
          0.5217391304583417,
          0.5106719371358397,
          0.5106719367824524,
          0.5177865616417685,
          0.5075098817998712,
          0.513043478637816,
          0.5043478264639029,
          0.5162055336203971,
          0.5075098817998712,
          0.5114624509698318,
          0.513833992471808,
          0.5075098817998712
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 1",
         "type": "scatter",
         "uid": "05ff3bde-811d-43d5-8421-2f3acd734853",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5098814233018476,
          0.5098814229484603,
          0.49723320160458684,
          0.5090909091144682,
          0.5051383399445077,
          0.505928854131887,
          0.498814229272571,
          0.5114624509698318,
          0.4940711466220057,
          0.49169960512002936,
          0.4996047431065631,
          0.5027667984425315,
          0.4956521739366026,
          0.5067193679658791,
          0.5067193676124919,
          0.5043478264167846,
          0.5146245063058001,
          0.5256916999816894,
          0.5201581031437448,
          0.515415019786405,
          0.5169960478077764,
          0.521739130811729,
          0.5185770751223734,
          0.5154150201397922,
          0.5209486169777369,
          0.5027667987959187,
          0.5011857711279345,
          0.5154150201397922,
          0.5083003956338633,
          0.5075098817998712,
          0.5185770754286423
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 2",
         "type": "scatter",
         "uid": "332e414a-c977-4eeb-894a-69644b06f03d",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5035573122765236,
          0.5027667984425315,
          0.5090909094207372,
          0.49090909128603727,
          0.5098814233018476,
          0.505928854131887,
          0.5075098817998712,
          0.5035573123236419,
          0.5003952572468241,
          0.488537549784061,
          0.5075098817998712,
          0.5035573122765236,
          0.5003952572468241,
          0.5122529648038239,
          0.5051383402507766,
          0.5177865616417685,
          0.5106719371358397,
          0.5019762849619266,
          0.5106719368295707,
          0.5083003956338633,
          0.5146245063058001,
          0.5146245063058001,
          0.5177865616417685,
          0.5067193676596102,
          0.5098814233018476,
          0.5146245063058001,
          0.5138339921184208,
          0.5043478264639029,
          0.507509881446484,
          0.5154150201397922,
          0.5067193679658791
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 3",
         "type": "scatter",
         "uid": "0b216ed9-0130-4d9d-837c-77b49dbb95d4",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.49249011895402145,
          0.5098814229484603,
          0.5019762849148083,
          0.505928854131887,
          0.5059288537784998,
          0.4996047434599503,
          0.5035573126299108,
          0.4996047434599503,
          0.5003952572468241,
          0.4893280636180531,
          0.5035573126299108,
          0.49802371543857893,
          0.513043478637816,
          0.5019762846085394,
          0.5106719371358397,
          0.5114624509227135,
          0.5122529648038239,
          0.515415019786405,
          0.5154150201397922,
          0.522529644645721,
          0.505138340297895,
          0.5169960478077764,
          0.5201581031437448,
          0.5106719371358397,
          0.4996047434599503,
          0.5169960478077764,
          0.5067193676124919,
          0.5146245063058001,
          0.5043478264639029,
          0.5043478261105157,
          0.5106719367824524
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 4",
         "type": "scatter",
         "uid": "2f9230fa-3bf5-47ea-b643-5e2650adb502",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.505138340297895,
          0.505928854131887,
          0.4948616604559978,
          0.5051383399445077,
          0.498814229272571,
          0.5122529647567056,
          0.49723320195797405,
          0.5146245063058001,
          0.505928854131887,
          0.4940711466220057,
          0.5106719368295707,
          0.5106719367824524,
          0.5027667987959187,
          0.5059288537784998,
          0.5083003956338633,
          0.5098814233018476,
          0.5138339921184208,
          0.5027667987959187,
          0.5146245059995312,
          0.5059288540847687,
          0.5130434783315471,
          0.5169960478077764,
          0.5114624509698318,
          0.505928854131887,
          0.505928854131887,
          0.5098814233018476,
          0.5114624509698318,
          0.5059288537784998,
          0.5130434783315471,
          0.49723320195797405,
          0.5114624509698318
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Test set accuracy of padded BERT dataset with variable maximum lengths"
        }
       }
      },
      "text/html": [
       "<div id=\"6142f664-ca53-4b83-9386-37ca9a91d9a5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {\n",
       "    Plotly.newPlot(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.513043478637816, 0.5122529648038239, 0.5075098817998712, 0.5083003953747127, 0.49407114631573673, 0.5098814233018476, 0.507509881752753, 0.5035573126299108, 0.4996047434599503, 0.5027667987488004, 0.507509881752753, 0.5090909091144682, 0.5067193679187609, 0.5114624509227135, 0.5098814233018476, 0.5162055336203971, 0.5193675893097527, 0.5193675893097527, 0.5233201584797131, 0.5217391304583417, 0.5106719371358397, 0.5106719367824524, 0.5177865616417685, 0.5075098817998712, 0.513043478637816, 0.5043478264639029, 0.5162055336203971, 0.5075098817998712, 0.5114624509698318, 0.513833992471808, 0.5075098817998712], \"type\": \"scatter\", \"uid\": \"36b39775-a328-4c54-a3ca-4455c6dc01d6\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5098814233018476, 0.5098814229484603, 0.49723320160458684, 0.5090909091144682, 0.5051383399445077, 0.505928854131887, 0.498814229272571, 0.5114624509698318, 0.4940711466220057, 0.49169960512002936, 0.4996047431065631, 0.5027667984425315, 0.4956521739366026, 0.5067193679658791, 0.5067193676124919, 0.5043478264167846, 0.5146245063058001, 0.5256916999816894, 0.5201581031437448, 0.515415019786405, 0.5169960478077764, 0.521739130811729, 0.5185770751223734, 0.5154150201397922, 0.5209486169777369, 0.5027667987959187, 0.5011857711279345, 0.5154150201397922, 0.5083003956338633, 0.5075098817998712, 0.5185770754286423], \"type\": \"scatter\", \"uid\": \"05ff3bde-811d-43d5-8421-2f3acd734853\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5035573122765236, 0.5027667984425315, 0.5090909094207372, 0.49090909128603727, 0.5098814233018476, 0.505928854131887, 0.5075098817998712, 0.5035573123236419, 0.5003952572468241, 0.488537549784061, 0.5075098817998712, 0.5035573122765236, 0.5003952572468241, 0.5122529648038239, 0.5051383402507766, 0.5177865616417685, 0.5106719371358397, 0.5019762849619266, 0.5106719368295707, 0.5083003956338633, 0.5146245063058001, 0.5146245063058001, 0.5177865616417685, 0.5067193676596102, 0.5098814233018476, 0.5146245063058001, 0.5138339921184208, 0.5043478264639029, 0.507509881446484, 0.5154150201397922, 0.5067193679658791], \"type\": \"scatter\", \"uid\": \"332e414a-c977-4eeb-894a-69644b06f03d\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.49249011895402145, 0.5098814229484603, 0.5019762849148083, 0.505928854131887, 0.5059288537784998, 0.4996047434599503, 0.5035573126299108, 0.4996047434599503, 0.5003952572468241, 0.4893280636180531, 0.5035573126299108, 0.49802371543857893, 0.513043478637816, 0.5019762846085394, 0.5106719371358397, 0.5114624509227135, 0.5122529648038239, 0.515415019786405, 0.5154150201397922, 0.522529644645721, 0.505138340297895, 0.5169960478077764, 0.5201581031437448, 0.5106719371358397, 0.4996047434599503, 0.5169960478077764, 0.5067193676124919, 0.5146245063058001, 0.5043478264639029, 0.5043478261105157, 0.5106719367824524], \"type\": \"scatter\", \"uid\": \"0b216ed9-0130-4d9d-837c-77b49dbb95d4\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 4\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505138340297895, 0.505928854131887, 0.4948616604559978, 0.5051383399445077, 0.498814229272571, 0.5122529647567056, 0.49723320195797405, 0.5146245063058001, 0.505928854131887, 0.4940711466220057, 0.5106719368295707, 0.5106719367824524, 0.5027667987959187, 0.5059288537784998, 0.5083003956338633, 0.5098814233018476, 0.5138339921184208, 0.5027667987959187, 0.5146245059995312, 0.5059288540847687, 0.5130434783315471, 0.5169960478077764, 0.5114624509698318, 0.505928854131887, 0.505928854131887, 0.5098814233018476, 0.5114624509698318, 0.5059288537784998, 0.5130434783315471, 0.49723320195797405, 0.5114624509698318], \"type\": \"scatter\", \"uid\": \"2f9230fa-3bf5-47ea-b643-5e2650adb502\"}], {\"title\": {\"text\": \"Test set accuracy of padded BERT dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {window._Plotly.Plots.resize(document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"6142f664-ca53-4b83-9386-37ca9a91d9a5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {\n",
       "    Plotly.newPlot(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.513043478637816, 0.5122529648038239, 0.5075098817998712, 0.5083003953747127, 0.49407114631573673, 0.5098814233018476, 0.507509881752753, 0.5035573126299108, 0.4996047434599503, 0.5027667987488004, 0.507509881752753, 0.5090909091144682, 0.5067193679187609, 0.5114624509227135, 0.5098814233018476, 0.5162055336203971, 0.5193675893097527, 0.5193675893097527, 0.5233201584797131, 0.5217391304583417, 0.5106719371358397, 0.5106719367824524, 0.5177865616417685, 0.5075098817998712, 0.513043478637816, 0.5043478264639029, 0.5162055336203971, 0.5075098817998712, 0.5114624509698318, 0.513833992471808, 0.5075098817998712], \"type\": \"scatter\", \"uid\": \"36b39775-a328-4c54-a3ca-4455c6dc01d6\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5098814233018476, 0.5098814229484603, 0.49723320160458684, 0.5090909091144682, 0.5051383399445077, 0.505928854131887, 0.498814229272571, 0.5114624509698318, 0.4940711466220057, 0.49169960512002936, 0.4996047431065631, 0.5027667984425315, 0.4956521739366026, 0.5067193679658791, 0.5067193676124919, 0.5043478264167846, 0.5146245063058001, 0.5256916999816894, 0.5201581031437448, 0.515415019786405, 0.5169960478077764, 0.521739130811729, 0.5185770751223734, 0.5154150201397922, 0.5209486169777369, 0.5027667987959187, 0.5011857711279345, 0.5154150201397922, 0.5083003956338633, 0.5075098817998712, 0.5185770754286423], \"type\": \"scatter\", \"uid\": \"05ff3bde-811d-43d5-8421-2f3acd734853\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5035573122765236, 0.5027667984425315, 0.5090909094207372, 0.49090909128603727, 0.5098814233018476, 0.505928854131887, 0.5075098817998712, 0.5035573123236419, 0.5003952572468241, 0.488537549784061, 0.5075098817998712, 0.5035573122765236, 0.5003952572468241, 0.5122529648038239, 0.5051383402507766, 0.5177865616417685, 0.5106719371358397, 0.5019762849619266, 0.5106719368295707, 0.5083003956338633, 0.5146245063058001, 0.5146245063058001, 0.5177865616417685, 0.5067193676596102, 0.5098814233018476, 0.5146245063058001, 0.5138339921184208, 0.5043478264639029, 0.507509881446484, 0.5154150201397922, 0.5067193679658791], \"type\": \"scatter\", \"uid\": \"332e414a-c977-4eeb-894a-69644b06f03d\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.49249011895402145, 0.5098814229484603, 0.5019762849148083, 0.505928854131887, 0.5059288537784998, 0.4996047434599503, 0.5035573126299108, 0.4996047434599503, 0.5003952572468241, 0.4893280636180531, 0.5035573126299108, 0.49802371543857893, 0.513043478637816, 0.5019762846085394, 0.5106719371358397, 0.5114624509227135, 0.5122529648038239, 0.515415019786405, 0.5154150201397922, 0.522529644645721, 0.505138340297895, 0.5169960478077764, 0.5201581031437448, 0.5106719371358397, 0.4996047434599503, 0.5169960478077764, 0.5067193676124919, 0.5146245063058001, 0.5043478264639029, 0.5043478261105157, 0.5106719367824524], \"type\": \"scatter\", \"uid\": \"0b216ed9-0130-4d9d-837c-77b49dbb95d4\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 4\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505138340297895, 0.505928854131887, 0.4948616604559978, 0.5051383399445077, 0.498814229272571, 0.5122529647567056, 0.49723320195797405, 0.5146245063058001, 0.505928854131887, 0.4940711466220057, 0.5106719368295707, 0.5106719367824524, 0.5027667987959187, 0.5059288537784998, 0.5083003956338633, 0.5098814233018476, 0.5138339921184208, 0.5027667987959187, 0.5146245059995312, 0.5059288540847687, 0.5130434783315471, 0.5169960478077764, 0.5114624509698318, 0.505928854131887, 0.505928854131887, 0.5098814233018476, 0.5114624509698318, 0.5059288537784998, 0.5130434783315471, 0.49723320195797405, 0.5114624509698318], \"type\": \"scatter\", \"uid\": \"2f9230fa-3bf5-47ea-b643-5e2650adb502\"}], {\"title\": {\"text\": \"Test set accuracy of padded BERT dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\")) {window._Plotly.Plots.resize(document.getElementById(\"6142f664-ca53-4b83-9386-37ca9a91d9a5\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traces = [round1, round2, round3, round4, round5]\n",
    "\n",
    "# Create traces\n",
    "bert_trace = go.Scatter(\n",
    "    x = list(round1.keys()),\n",
    "    y = list(round1.values()),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'BERT'\n",
    ")\n",
    "\n",
    "def create_scatter(counter):\n",
    "    acc_dict = traces[counter]\n",
    "    \n",
    "    return go.Scatter(\n",
    "        x = list(acc_dict.keys()),\n",
    "        y = list(acc_dict.values()),\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Round ' + str(counter)\n",
    "    )\n",
    "\n",
    "trace_data = [create_scatter(trace) for trace in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Test set accuracy of padded BERT dataset with variable maximum lengths',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = trace_data, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = data.get_elmo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_round(dataset):\n",
    "    # Store accuracies\n",
    "    accuracies = {\n",
    "        padding_len: 0.0 for padding_len in list(range(5,36))\n",
    "    }\n",
    "\n",
    "    for max_len in accuracies.keys():\n",
    "        padded_dataset = {\n",
    "            fold: sequence.pad_sequences(dataset[fold], maxlen = max_len, dtype = float)\n",
    "            for fold in dataset.keys()\n",
    "        }\n",
    "\n",
    "        accuracies[max_len] = get_bilstm_score(padded_dataset['train'], padded_dataset['test'], padded_dataset['validation'], reshape = False)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-06-03 19:48:57,899 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-06-03 19:49:01,164 From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2019-06-03 19:49:01,360 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.1124 - acc: 0.4187 - val_loss: 1.0269 - val_acc: 0.5023\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 15s 1ms/step - loss: 1.0569 - acc: 0.4598 - val_loss: 1.0214 - val_acc: 0.5109\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 14s 1ms/step - loss: 1.0382 - acc: 0.4776 - val_loss: 1.0143 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 14s 1ms/step - loss: 1.0307 - acc: 0.4889 - val_loss: 1.0105 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 14s 1ms/step - loss: 1.0220 - acc: 0.4888 - val_loss: 1.0118 - val_acc: 0.5093\n",
      "1265/1265 [==============================] - 1s 922us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.1208 - acc: 0.4218 - val_loss: 1.0210 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 15s 1ms/step - loss: 1.0588 - acc: 0.4541 - val_loss: 1.0181 - val_acc: 0.5070\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 15s 1ms/step - loss: 1.0400 - acc: 0.4711 - val_loss: 1.0149 - val_acc: 0.5070\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 15s 1ms/step - loss: 1.0298 - acc: 0.4835 - val_loss: 1.0147 - val_acc: 0.5109\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 15s 1ms/step - loss: 1.0250 - acc: 0.4897 - val_loss: 1.0138 - val_acc: 0.5093\n",
      "1265/1265 [==============================] - 1s 449us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.1260 - acc: 0.4131 - val_loss: 1.0174 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0514 - acc: 0.4653 - val_loss: 1.0179 - val_acc: 0.5055\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0407 - acc: 0.4754 - val_loss: 1.0083 - val_acc: 0.5164\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0279 - acc: 0.4866 - val_loss: 1.0067 - val_acc: 0.5195\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 17s 2ms/step - loss: 1.0207 - acc: 0.4977 - val_loss: 1.0055 - val_acc: 0.5218\n",
      "1265/1265 [==============================] - 1s 540us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 20s 2ms/step - loss: 1.1196 - acc: 0.4259 - val_loss: 1.0152 - val_acc: 0.5109\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0528 - acc: 0.4597 - val_loss: 1.0072 - val_acc: 0.5117\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0361 - acc: 0.4769 - val_loss: 1.0112 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0257 - acc: 0.4897 - val_loss: 1.0068 - val_acc: 0.5171\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 18s 2ms/step - loss: 1.0160 - acc: 0.5016 - val_loss: 1.0033 - val_acc: 0.5125\n",
      "1265/1265 [==============================] - 1s 589us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.1207 - acc: 0.4199 - val_loss: 1.0161 - val_acc: 0.5008\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 20s 2ms/step - loss: 1.0536 - acc: 0.4636 - val_loss: 1.0092 - val_acc: 0.5039\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 20s 2ms/step - loss: 1.0389 - acc: 0.4780 - val_loss: 1.0099 - val_acc: 0.5101\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 20s 2ms/step - loss: 1.0264 - acc: 0.4894 - val_loss: 1.0092 - val_acc: 0.5109\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 20s 2ms/step - loss: 1.0175 - acc: 0.4946 - val_loss: 1.0047 - val_acc: 0.5195\n",
      "1265/1265 [==============================] - 1s 649us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.1099 - acc: 0.4214 - val_loss: 1.0153 - val_acc: 0.5179\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0495 - acc: 0.4604 - val_loss: 1.0132 - val_acc: 0.5187\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0314 - acc: 0.4850 - val_loss: 1.0076 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0256 - acc: 0.4860 - val_loss: 1.0032 - val_acc: 0.5226\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 22s 2ms/step - loss: 1.0196 - acc: 0.4970 - val_loss: 1.0018 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 1s 738us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 25s 2ms/step - loss: 1.1255 - acc: 0.4119 - val_loss: 1.0165 - val_acc: 0.5148\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0464 - acc: 0.4675 - val_loss: 1.0129 - val_acc: 0.5117\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0369 - acc: 0.4801 - val_loss: 1.0070 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 24s 2ms/step - loss: 1.0272 - acc: 0.4892 - val_loss: 0.9991 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 23s 2ms/step - loss: 1.0187 - acc: 0.4973 - val_loss: 1.0001 - val_acc: 0.5202\n",
      "1265/1265 [==============================] - 1s 789us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.1161 - acc: 0.4279 - val_loss: 1.0125 - val_acc: 0.5202\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0535 - acc: 0.4691 - val_loss: 1.0047 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0364 - acc: 0.4827 - val_loss: 0.9994 - val_acc: 0.5125\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0200 - acc: 0.4969 - val_loss: 0.9984 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 26s 3ms/step - loss: 1.0180 - acc: 0.5033 - val_loss: 0.9984 - val_acc: 0.5187\n",
      "1265/1265 [==============================] - 1s 911us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.1097 - acc: 0.4263 - val_loss: 1.0157 - val_acc: 0.5179\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 27s 3ms/step - loss: 1.0500 - acc: 0.4713 - val_loss: 1.0073 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 27s 3ms/step - loss: 1.0369 - acc: 0.4813 - val_loss: 1.0048 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0229 - acc: 0.4991 - val_loss: 1.0055 - val_acc: 0.5187\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0158 - acc: 0.5027 - val_loss: 0.9966 - val_acc: 0.5187\n",
      "1265/1265 [==============================] - 1s 984us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 32s 3ms/step - loss: 1.1148 - acc: 0.4288 - val_loss: 1.0110 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0474 - acc: 0.4688 - val_loss: 1.0076 - val_acc: 0.5047\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 28s 3ms/step - loss: 1.0346 - acc: 0.4838 - val_loss: 1.0009 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0200 - acc: 0.5038 - val_loss: 0.9952 - val_acc: 0.5156\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 29s 3ms/step - loss: 1.0125 - acc: 0.5072 - val_loss: 0.9964 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 1s 986us/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 34s 3ms/step - loss: 1.1140 - acc: 0.4199 - val_loss: 1.0181 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0511 - acc: 0.4710 - val_loss: 1.0109 - val_acc: 0.5132\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0343 - acc: 0.4820 - val_loss: 1.0019 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0300 - acc: 0.4904 - val_loss: 1.0024 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 30s 3ms/step - loss: 1.0223 - acc: 0.4946 - val_loss: 0.9971 - val_acc: 0.5187\n",
      "1265/1265 [==============================] - 1s 1ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 46s 4ms/step - loss: 1.1154 - acc: 0.4243 - val_loss: 1.0141 - val_acc: 0.5210\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 32s 3ms/step - loss: 1.0503 - acc: 0.4681 - val_loss: 1.0089 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0360 - acc: 0.4833 - val_loss: 1.0014 - val_acc: 0.5156\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0230 - acc: 0.4949 - val_loss: 0.9989 - val_acc: 0.5195\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0142 - acc: 0.5015 - val_loss: 0.9965 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 3s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.1077 - acc: 0.4353 - val_loss: 1.0162 - val_acc: 0.5187\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0502 - acc: 0.4713 - val_loss: 1.0072 - val_acc: 0.5218\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 32s 3ms/step - loss: 1.0311 - acc: 0.4883 - val_loss: 1.0034 - val_acc: 0.5171\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0211 - acc: 0.4962 - val_loss: 1.0005 - val_acc: 0.5164\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 31s 3ms/step - loss: 1.0139 - acc: 0.5084 - val_loss: 1.0007 - val_acc: 0.5101\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.1098 - acc: 0.4276 - val_loss: 1.0179 - val_acc: 0.5148\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 41s 4ms/step - loss: 1.0514 - acc: 0.4729 - val_loss: 1.0082 - val_acc: 0.5187\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0346 - acc: 0.4890 - val_loss: 1.0098 - val_acc: 0.5226\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0238 - acc: 0.4911 - val_loss: 1.0072 - val_acc: 0.5234\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 33s 3ms/step - loss: 1.0122 - acc: 0.5091 - val_loss: 0.9956 - val_acc: 0.5164\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 61s 6ms/step - loss: 1.1006 - acc: 0.4257 - val_loss: 1.0200 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0475 - acc: 0.4738 - val_loss: 1.0110 - val_acc: 0.5265\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0341 - acc: 0.4839 - val_loss: 1.0031 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0287 - acc: 0.4959 - val_loss: 0.9996 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 36s 4ms/step - loss: 1.0116 - acc: 0.5026 - val_loss: 0.9974 - val_acc: 0.5249\n",
      "1265/1265 [==============================] - 4s 3ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.1081 - acc: 0.4254 - val_loss: 1.0141 - val_acc: 0.5187\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0531 - acc: 0.4634 - val_loss: 1.0134 - val_acc: 0.5312\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0352 - acc: 0.4817 - val_loss: 1.0043 - val_acc: 0.5296\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 37s 4ms/step - loss: 1.0260 - acc: 0.4994 - val_loss: 1.0028 - val_acc: 0.5312\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 38s 4ms/step - loss: 1.0156 - acc: 0.5071 - val_loss: 0.9965 - val_acc: 0.5288\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 67s 7ms/step - loss: 1.1107 - acc: 0.4101 - val_loss: 1.0167 - val_acc: 0.4984\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0601 - acc: 0.4616 - val_loss: 1.0159 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 39s 4ms/step - loss: 1.0417 - acc: 0.4763 - val_loss: 1.0102 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 39s 4ms/step - loss: 1.0243 - acc: 0.4907 - val_loss: 1.0029 - val_acc: 0.5257\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 39s 4ms/step - loss: 1.0214 - acc: 0.4978 - val_loss: 1.0016 - val_acc: 0.5132\n",
      "1265/1265 [==============================] - 4s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 65s 6ms/step - loss: 1.1088 - acc: 0.4277 - val_loss: 1.0204 - val_acc: 0.5078\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 50s 5ms/step - loss: 1.0568 - acc: 0.4615 - val_loss: 1.0123 - val_acc: 0.5047\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0388 - acc: 0.4808 - val_loss: 1.0071 - val_acc: 0.5164\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0266 - acc: 0.4903 - val_loss: 1.0017 - val_acc: 0.5132\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 40s 4ms/step - loss: 1.0198 - acc: 0.4977 - val_loss: 0.9998 - val_acc: 0.5241\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 73s 7ms/step - loss: 1.0989 - acc: 0.4231 - val_loss: 1.0232 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 53s 5ms/step - loss: 1.0570 - acc: 0.4630 - val_loss: 1.0183 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0368 - acc: 0.4765 - val_loss: 1.0069 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0318 - acc: 0.4830 - val_loss: 1.0118 - val_acc: 0.5164\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 42s 4ms/step - loss: 1.0196 - acc: 0.4984 - val_loss: 1.0058 - val_acc: 0.5234\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.1023 - acc: 0.4293 - val_loss: 1.0194 - val_acc: 0.5078\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0562 - acc: 0.4656 - val_loss: 1.0108 - val_acc: 0.5210\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 46s 4ms/step - loss: 1.0369 - acc: 0.4832 - val_loss: 1.0044 - val_acc: 0.5218\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0264 - acc: 0.4930 - val_loss: 1.0080 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 44s 4ms/step - loss: 1.0193 - acc: 0.5012 - val_loss: 0.9983 - val_acc: 0.5265\n",
      "1265/1265 [==============================] - 5s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 72s 7ms/step - loss: 1.0979 - acc: 0.4254 - val_loss: 1.0219 - val_acc: 0.5125\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0534 - acc: 0.4696 - val_loss: 1.0102 - val_acc: 0.5304\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0398 - acc: 0.4736 - val_loss: 1.0074 - val_acc: 0.5327\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0291 - acc: 0.4943 - val_loss: 1.0028 - val_acc: 0.5296\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 45s 4ms/step - loss: 1.0197 - acc: 0.5018 - val_loss: 1.0055 - val_acc: 0.5234\n",
      "1265/1265 [==============================] - 6s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 77s 8ms/step - loss: 1.0951 - acc: 0.4253 - val_loss: 1.0233 - val_acc: 0.5086\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0571 - acc: 0.4653 - val_loss: 1.0146 - val_acc: 0.5148\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0421 - acc: 0.4798 - val_loss: 1.0091 - val_acc: 0.5195\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0270 - acc: 0.5000 - val_loss: 0.9981 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 47s 5ms/step - loss: 1.0245 - acc: 0.4951 - val_loss: 1.0011 - val_acc: 0.5164\n",
      "1265/1265 [==============================] - 6s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 82s 8ms/step - loss: 1.0923 - acc: 0.4292 - val_loss: 1.0184 - val_acc: 0.5016\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 59s 6ms/step - loss: 1.0523 - acc: 0.4658 - val_loss: 1.0114 - val_acc: 0.5241\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0389 - acc: 0.4830 - val_loss: 1.0099 - val_acc: 0.5234\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0248 - acc: 0.4943 - val_loss: 0.9948 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 49s 5ms/step - loss: 1.0215 - acc: 0.4974 - val_loss: 1.0001 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 6s 4ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 84s 8ms/step - loss: 1.0944 - acc: 0.4266 - val_loss: 1.0155 - val_acc: 0.5156\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 62s 6ms/step - loss: 1.0572 - acc: 0.4660 - val_loss: 1.0091 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 52s 5ms/step - loss: 1.0393 - acc: 0.4807 - val_loss: 1.0070 - val_acc: 0.5187\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0288 - acc: 0.4896 - val_loss: 1.0003 - val_acc: 0.5288\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 51s 5ms/step - loss: 1.0218 - acc: 0.4921 - val_loss: 0.9978 - val_acc: 0.5249\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 85s 8ms/step - loss: 1.0863 - acc: 0.4333 - val_loss: 1.0241 - val_acc: 0.5055\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0496 - acc: 0.4657 - val_loss: 1.0147 - val_acc: 0.5109\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 52s 5ms/step - loss: 1.0393 - acc: 0.4779 - val_loss: 1.0052 - val_acc: 0.5241\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 52s 5ms/step - loss: 1.0301 - acc: 0.4944 - val_loss: 1.0045 - val_acc: 0.5234\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 52s 5ms/step - loss: 1.0199 - acc: 0.5034 - val_loss: 1.0056 - val_acc: 0.5234\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 85s 8ms/step - loss: 1.0923 - acc: 0.4328 - val_loss: 1.0251 - val_acc: 0.5023\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 65s 6ms/step - loss: 1.0577 - acc: 0.4578 - val_loss: 1.0114 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0455 - acc: 0.4724 - val_loss: 1.0076 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 54s 5ms/step - loss: 1.0320 - acc: 0.4851 - val_loss: 1.0062 - val_acc: 0.5179\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.0251 - acc: 0.4910 - val_loss: 0.9999 - val_acc: 0.5171\n",
      "1265/1265 [==============================] - 6s 5ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 87s 8ms/step - loss: 1.0927 - acc: 0.4302 - val_loss: 1.0242 - val_acc: 0.4930\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 68s 7ms/step - loss: 1.0460 - acc: 0.4713 - val_loss: 1.0154 - val_acc: 0.5031\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 56s 5ms/step - loss: 1.0414 - acc: 0.4818 - val_loss: 1.0037 - val_acc: 0.5179\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0322 - acc: 0.4877 - val_loss: 1.0014 - val_acc: 0.5195\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 55s 5ms/step - loss: 1.0195 - acc: 0.5015 - val_loss: 0.9995 - val_acc: 0.5312\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 92s 9ms/step - loss: 1.0896 - acc: 0.4225 - val_loss: 1.0207 - val_acc: 0.5023\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 69s 7ms/step - loss: 1.0525 - acc: 0.4686 - val_loss: 1.0121 - val_acc: 0.5195\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0394 - acc: 0.4813 - val_loss: 1.0087 - val_acc: 0.5140\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 57s 6ms/step - loss: 1.0347 - acc: 0.4810 - val_loss: 1.0007 - val_acc: 0.5202\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 58s 6ms/step - loss: 1.0243 - acc: 0.4981 - val_loss: 1.0005 - val_acc: 0.5210\n",
      "1265/1265 [==============================] - 7s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 98s 10ms/step - loss: 1.0792 - acc: 0.4404 - val_loss: 1.0173 - val_acc: 0.5195\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 77s 8ms/step - loss: 1.0552 - acc: 0.4652 - val_loss: 1.0155 - val_acc: 0.5210\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0374 - acc: 0.4847 - val_loss: 1.0031 - val_acc: 0.5249\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 70s 7ms/step - loss: 1.0298 - acc: 0.4928 - val_loss: 1.0040 - val_acc: 0.5249\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10235/10235 [==============================] - 64s 6ms/step - loss: 1.0242 - acc: 0.4944 - val_loss: 0.9969 - val_acc: 0.5358\n",
      "1265/1265 [==============================] - 8s 6ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 102s 10ms/step - loss: 1.0826 - acc: 0.4299 - val_loss: 1.0253 - val_acc: 0.4953\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 117s 11ms/step - loss: 1.0539 - acc: 0.4582 - val_loss: 1.0211 - val_acc: 0.5070\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 78s 8ms/step - loss: 1.0406 - acc: 0.4720 - val_loss: 1.0168 - val_acc: 0.5109\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 74s 7ms/step - loss: 1.0349 - acc: 0.4787 - val_loss: 1.0095 - val_acc: 0.5117\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 74s 7ms/step - loss: 1.0262 - acc: 0.4953 - val_loss: 1.0057 - val_acc: 0.5156\n",
      "1265/1265 [==============================] - 9s 7ms/step\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 111s 11ms/step - loss: 1.0858 - acc: 0.4239 - val_loss: 1.0209 - val_acc: 0.4977\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 91s 9ms/step - loss: 1.0513 - acc: 0.4631 - val_loss: 1.0102 - val_acc: 0.5140\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.0395 - acc: 0.4827 - val_loss: 1.0171 - val_acc: 0.5132\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.0316 - acc: 0.4893 - val_loss: 1.0073 - val_acc: 0.5241\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 76s 7ms/step - loss: 1.0260 - acc: 0.4939 - val_loss: 1.0011 - val_acc: 0.5187\n",
      "1265/1265 [==============================] - 9s 7ms/step\n",
      "CPU times: user 7h 48min 51s, sys: 2h 1min 19s, total: 9h 50min 11s\n",
      "Wall time: 2h 14min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "concatenated_elmo = {\n",
    "    fold: [np.concatenate(np.array(statement)) for statement in elmo[fold]['statement']]\n",
    "    for fold in elmo.keys()\n",
    "}\n",
    "\n",
    "elmo_rounds = [calculate_round(concatenated_elmo) for round in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{5: 0.5177865616417685,\n",
       "  6: 0.5241106722665869,\n",
       "  7: 0.5114624509698318,\n",
       "  8: 0.5067193676124919,\n",
       "  9: 0.5067193679187609,\n",
       "  10: 0.5059288540847687,\n",
       "  11: 0.49802371574484783,\n",
       "  12: 0.5011857710808162,\n",
       "  13: 0.49169960507291105,\n",
       "  14: 0.49723320191085574,\n",
       "  15: 0.4932806327408953,\n",
       "  16: 0.5169960478077764,\n",
       "  17: 0.5154150200455556,\n",
       "  18: 0.513043478637816,\n",
       "  19: 0.5083003955396268,\n",
       "  20: 0.5185770754286423,\n",
       "  21: 0.5067193679187609,\n",
       "  22: 0.5146245063058001,\n",
       "  23: 0.5011857710808162,\n",
       "  24: 0.5106719370887214,\n",
       "  25: 0.5169960477606581,\n",
       "  26: 0.5193675893097527,\n",
       "  27: 0.5114624509227135,\n",
       "  28: 0.5130434785906977,\n",
       "  29: 0.5241106723137052,\n",
       "  30: 0.5169960477606581,\n",
       "  31: 0.5169960477606581,\n",
       "  32: 0.5146245063058001,\n",
       "  33: 0.5185770754286423,\n",
       "  34: 0.5051383402507766,\n",
       "  35: 0.5035573125827925},\n",
       " {5: 0.5122529647567056,\n",
       "  6: 0.5169960478077764,\n",
       "  7: 0.5146245062586818,\n",
       "  8: 0.5233201584325948,\n",
       "  9: 0.5138339924246897,\n",
       "  10: 0.4996047434599503,\n",
       "  11: 0.49090909123891896,\n",
       "  12: 0.49090909123891896,\n",
       "  13: 0.5011857710808162,\n",
       "  14: 0.5051383402036584,\n",
       "  15: 0.5067193679187609,\n",
       "  16: 0.5122529648038239,\n",
       "  17: 0.5146245062586818,\n",
       "  18: 0.5146245062586818,\n",
       "  19: 0.516205533926666,\n",
       "  20: 0.5083003955867451,\n",
       "  21: 0.5304347829385238,\n",
       "  22: 0.5217391307646106,\n",
       "  23: 0.5106719370887214,\n",
       "  24: 0.5138339924246897,\n",
       "  25: 0.5209486169306186,\n",
       "  26: 0.5233201584325948,\n",
       "  27: 0.505138340297895,\n",
       "  28: 0.5201581030966265,\n",
       "  29: 0.5225296445986027,\n",
       "  30: 0.5098814233018476,\n",
       "  31: 0.5090909094207372,\n",
       "  32: 0.5122529647567056,\n",
       "  33: 0.5130434785906977,\n",
       "  34: 0.499604743412832,\n",
       "  35: 0.5154150200926739},\n",
       " {5: 0.516205533926666,\n",
       "  6: 0.5264822137685633,\n",
       "  7: 0.5146245062586818,\n",
       "  8: 0.5067193679187609,\n",
       "  9: 0.505928854131887,\n",
       "  10: 0.5035573125827925,\n",
       "  11: 0.4988142295788399,\n",
       "  12: 0.5146245063058001,\n",
       "  13: 0.4940711465748874,\n",
       "  14: 0.5035573125827925,\n",
       "  15: 0.5083003955867451,\n",
       "  16: 0.5067193679187609,\n",
       "  17: 0.5098814232547293,\n",
       "  18: 0.5177865616417685,\n",
       "  19: 0.5059288540847687,\n",
       "  20: 0.513043478637816,\n",
       "  21: 0.5067193679187609,\n",
       "  22: 0.5312252967725158,\n",
       "  23: 0.5209486169306186,\n",
       "  24: 0.5122529647567056,\n",
       "  25: 0.5138339924246897,\n",
       "  26: 0.5185770754757606,\n",
       "  27: 0.5169960478077764,\n",
       "  28: 0.5177865616417685,\n",
       "  29: 0.5193675892626344,\n",
       "  30: 0.5185770754286423,\n",
       "  31: 0.5043478264167846,\n",
       "  32: 0.5090909094678555,\n",
       "  33: 0.5177865616417685,\n",
       "  34: 0.5138339924246897,\n",
       "  35: 0.5098814232547293},\n",
       " {5: 0.505928854131887,\n",
       "  6: 0.5241106723137052,\n",
       "  7: 0.5003952572468241,\n",
       "  8: 0.5154150201397922,\n",
       "  9: 0.4996047431065631,\n",
       "  10: 0.5019762849148083,\n",
       "  11: 0.49802371543857893,\n",
       "  12: 0.5011857710808162,\n",
       "  13: 0.5003952572468241,\n",
       "  14: 0.5122529648038239,\n",
       "  15: 0.5083003955867451,\n",
       "  16: 0.5114624509227135,\n",
       "  17: 0.5169960477606581,\n",
       "  18: 0.5090909094207372,\n",
       "  19: 0.516205533926666,\n",
       "  20: 0.49802371574484783,\n",
       "  21: 0.5177865615946502,\n",
       "  22: 0.5106719370887214,\n",
       "  23: 0.5177865612883813,\n",
       "  24: 0.5193675892626344,\n",
       "  25: 0.5177865616417685,\n",
       "  26: 0.5122529648038239,\n",
       "  27: 0.5154150200926739,\n",
       "  28: 0.5122529648038239,\n",
       "  29: 0.4988142295788399,\n",
       "  30: 0.516205533926666,\n",
       "  31: 0.5035573126299108,\n",
       "  32: 0.5106719370887214,\n",
       "  33: 0.5098814232547293,\n",
       "  34: 0.513833992471808,\n",
       "  35: 0.5225296445986027}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Round 0",
         "type": "scatter",
         "uid": "f6799707-7b3e-4332-8ae9-3b90154bf1b9",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5177865616417685,
          0.5241106722665869,
          0.5114624509698318,
          0.5067193676124919,
          0.5067193679187609,
          0.5059288540847687,
          0.49802371574484783,
          0.5011857710808162,
          0.49169960507291105,
          0.49723320191085574,
          0.4932806327408953,
          0.5169960478077764,
          0.5154150200455556,
          0.513043478637816,
          0.5083003955396268,
          0.5185770754286423,
          0.5067193679187609,
          0.5146245063058001,
          0.5011857710808162,
          0.5106719370887214,
          0.5169960477606581,
          0.5193675893097527,
          0.5114624509227135,
          0.5130434785906977,
          0.5241106723137052,
          0.5169960477606581,
          0.5169960477606581,
          0.5146245063058001,
          0.5185770754286423,
          0.5051383402507766,
          0.5035573125827925
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 1",
         "type": "scatter",
         "uid": "6e7703a0-018e-442a-b0de-40ced63000e7",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5122529647567056,
          0.5169960478077764,
          0.5146245062586818,
          0.5233201584325948,
          0.5138339924246897,
          0.4996047434599503,
          0.49090909123891896,
          0.49090909123891896,
          0.5011857710808162,
          0.5051383402036584,
          0.5067193679187609,
          0.5122529648038239,
          0.5146245062586818,
          0.5146245062586818,
          0.516205533926666,
          0.5083003955867451,
          0.5304347829385238,
          0.5217391307646106,
          0.5106719370887214,
          0.5138339924246897,
          0.5209486169306186,
          0.5233201584325948,
          0.505138340297895,
          0.5201581030966265,
          0.5225296445986027,
          0.5098814233018476,
          0.5090909094207372,
          0.5122529647567056,
          0.5130434785906977,
          0.499604743412832,
          0.5154150200926739
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 2",
         "type": "scatter",
         "uid": "c54f4768-094c-4b71-8c0d-95543345190e",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.516205533926666,
          0.5264822137685633,
          0.5146245062586818,
          0.5067193679187609,
          0.505928854131887,
          0.5035573125827925,
          0.4988142295788399,
          0.5146245063058001,
          0.4940711465748874,
          0.5035573125827925,
          0.5083003955867451,
          0.5067193679187609,
          0.5098814232547293,
          0.5177865616417685,
          0.5059288540847687,
          0.513043478637816,
          0.5067193679187609,
          0.5312252967725158,
          0.5209486169306186,
          0.5122529647567056,
          0.5138339924246897,
          0.5185770754757606,
          0.5169960478077764,
          0.5177865616417685,
          0.5193675892626344,
          0.5185770754286423,
          0.5043478264167846,
          0.5090909094678555,
          0.5177865616417685,
          0.5138339924246897,
          0.5098814232547293
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Round 3",
         "type": "scatter",
         "uid": "0ab64927-aba1-4d64-acae-0e30d0eb38d7",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.505928854131887,
          0.5241106723137052,
          0.5003952572468241,
          0.5154150201397922,
          0.4996047431065631,
          0.5019762849148083,
          0.49802371543857893,
          0.5011857710808162,
          0.5003952572468241,
          0.5122529648038239,
          0.5083003955867451,
          0.5114624509227135,
          0.5169960477606581,
          0.5090909094207372,
          0.516205533926666,
          0.49802371574484783,
          0.5177865615946502,
          0.5106719370887214,
          0.5177865612883813,
          0.5193675892626344,
          0.5177865616417685,
          0.5122529648038239,
          0.5154150200926739,
          0.5122529648038239,
          0.4988142295788399,
          0.516205533926666,
          0.5035573126299108,
          0.5106719370887214,
          0.5098814232547293,
          0.513833992471808,
          0.5225296445986027
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Test set accuracy of padded ELMo dataset with variable maximum lengths"
        }
       }
      },
      "text/html": [
       "<div id=\"ceb41446-7291-4831-b10b-bc7edf632382\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\")) {\n",
       "    Plotly.newPlot(\"ceb41446-7291-4831-b10b-bc7edf632382\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5177865616417685, 0.5241106722665869, 0.5114624509698318, 0.5067193676124919, 0.5067193679187609, 0.5059288540847687, 0.49802371574484783, 0.5011857710808162, 0.49169960507291105, 0.49723320191085574, 0.4932806327408953, 0.5169960478077764, 0.5154150200455556, 0.513043478637816, 0.5083003955396268, 0.5185770754286423, 0.5067193679187609, 0.5146245063058001, 0.5011857710808162, 0.5106719370887214, 0.5169960477606581, 0.5193675893097527, 0.5114624509227135, 0.5130434785906977, 0.5241106723137052, 0.5169960477606581, 0.5169960477606581, 0.5146245063058001, 0.5185770754286423, 0.5051383402507766, 0.5035573125827925], \"type\": \"scatter\", \"uid\": \"f6799707-7b3e-4332-8ae9-3b90154bf1b9\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5122529647567056, 0.5169960478077764, 0.5146245062586818, 0.5233201584325948, 0.5138339924246897, 0.4996047434599503, 0.49090909123891896, 0.49090909123891896, 0.5011857710808162, 0.5051383402036584, 0.5067193679187609, 0.5122529648038239, 0.5146245062586818, 0.5146245062586818, 0.516205533926666, 0.5083003955867451, 0.5304347829385238, 0.5217391307646106, 0.5106719370887214, 0.5138339924246897, 0.5209486169306186, 0.5233201584325948, 0.505138340297895, 0.5201581030966265, 0.5225296445986027, 0.5098814233018476, 0.5090909094207372, 0.5122529647567056, 0.5130434785906977, 0.499604743412832, 0.5154150200926739], \"type\": \"scatter\", \"uid\": \"6e7703a0-018e-442a-b0de-40ced63000e7\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.516205533926666, 0.5264822137685633, 0.5146245062586818, 0.5067193679187609, 0.505928854131887, 0.5035573125827925, 0.4988142295788399, 0.5146245063058001, 0.4940711465748874, 0.5035573125827925, 0.5083003955867451, 0.5067193679187609, 0.5098814232547293, 0.5177865616417685, 0.5059288540847687, 0.513043478637816, 0.5067193679187609, 0.5312252967725158, 0.5209486169306186, 0.5122529647567056, 0.5138339924246897, 0.5185770754757606, 0.5169960478077764, 0.5177865616417685, 0.5193675892626344, 0.5185770754286423, 0.5043478264167846, 0.5090909094678555, 0.5177865616417685, 0.5138339924246897, 0.5098814232547293], \"type\": \"scatter\", \"uid\": \"c54f4768-094c-4b71-8c0d-95543345190e\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505928854131887, 0.5241106723137052, 0.5003952572468241, 0.5154150201397922, 0.4996047431065631, 0.5019762849148083, 0.49802371543857893, 0.5011857710808162, 0.5003952572468241, 0.5122529648038239, 0.5083003955867451, 0.5114624509227135, 0.5169960477606581, 0.5090909094207372, 0.516205533926666, 0.49802371574484783, 0.5177865615946502, 0.5106719370887214, 0.5177865612883813, 0.5193675892626344, 0.5177865616417685, 0.5122529648038239, 0.5154150200926739, 0.5122529648038239, 0.4988142295788399, 0.516205533926666, 0.5035573126299108, 0.5106719370887214, 0.5098814232547293, 0.513833992471808, 0.5225296445986027], \"type\": \"scatter\", \"uid\": \"0ab64927-aba1-4d64-acae-0e30d0eb38d7\"}], {\"title\": {\"text\": \"Test set accuracy of padded ELMo dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\")) {window._Plotly.Plots.resize(document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ceb41446-7291-4831-b10b-bc7edf632382\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\")) {\n",
       "    Plotly.newPlot(\"ceb41446-7291-4831-b10b-bc7edf632382\", [{\"mode\": \"lines+markers\", \"name\": \"Round 0\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5177865616417685, 0.5241106722665869, 0.5114624509698318, 0.5067193676124919, 0.5067193679187609, 0.5059288540847687, 0.49802371574484783, 0.5011857710808162, 0.49169960507291105, 0.49723320191085574, 0.4932806327408953, 0.5169960478077764, 0.5154150200455556, 0.513043478637816, 0.5083003955396268, 0.5185770754286423, 0.5067193679187609, 0.5146245063058001, 0.5011857710808162, 0.5106719370887214, 0.5169960477606581, 0.5193675893097527, 0.5114624509227135, 0.5130434785906977, 0.5241106723137052, 0.5169960477606581, 0.5169960477606581, 0.5146245063058001, 0.5185770754286423, 0.5051383402507766, 0.5035573125827925], \"type\": \"scatter\", \"uid\": \"f6799707-7b3e-4332-8ae9-3b90154bf1b9\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 1\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5122529647567056, 0.5169960478077764, 0.5146245062586818, 0.5233201584325948, 0.5138339924246897, 0.4996047434599503, 0.49090909123891896, 0.49090909123891896, 0.5011857710808162, 0.5051383402036584, 0.5067193679187609, 0.5122529648038239, 0.5146245062586818, 0.5146245062586818, 0.516205533926666, 0.5083003955867451, 0.5304347829385238, 0.5217391307646106, 0.5106719370887214, 0.5138339924246897, 0.5209486169306186, 0.5233201584325948, 0.505138340297895, 0.5201581030966265, 0.5225296445986027, 0.5098814233018476, 0.5090909094207372, 0.5122529647567056, 0.5130434785906977, 0.499604743412832, 0.5154150200926739], \"type\": \"scatter\", \"uid\": \"6e7703a0-018e-442a-b0de-40ced63000e7\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 2\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.516205533926666, 0.5264822137685633, 0.5146245062586818, 0.5067193679187609, 0.505928854131887, 0.5035573125827925, 0.4988142295788399, 0.5146245063058001, 0.4940711465748874, 0.5035573125827925, 0.5083003955867451, 0.5067193679187609, 0.5098814232547293, 0.5177865616417685, 0.5059288540847687, 0.513043478637816, 0.5067193679187609, 0.5312252967725158, 0.5209486169306186, 0.5122529647567056, 0.5138339924246897, 0.5185770754757606, 0.5169960478077764, 0.5177865616417685, 0.5193675892626344, 0.5185770754286423, 0.5043478264167846, 0.5090909094678555, 0.5177865616417685, 0.5138339924246897, 0.5098814232547293], \"type\": \"scatter\", \"uid\": \"c54f4768-094c-4b71-8c0d-95543345190e\"}, {\"mode\": \"lines+markers\", \"name\": \"Round 3\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.505928854131887, 0.5241106723137052, 0.5003952572468241, 0.5154150201397922, 0.4996047431065631, 0.5019762849148083, 0.49802371543857893, 0.5011857710808162, 0.5003952572468241, 0.5122529648038239, 0.5083003955867451, 0.5114624509227135, 0.5169960477606581, 0.5090909094207372, 0.516205533926666, 0.49802371574484783, 0.5177865615946502, 0.5106719370887214, 0.5177865612883813, 0.5193675892626344, 0.5177865616417685, 0.5122529648038239, 0.5154150200926739, 0.5122529648038239, 0.4988142295788399, 0.516205533926666, 0.5035573126299108, 0.5106719370887214, 0.5098814232547293, 0.513833992471808, 0.5225296445986027], \"type\": \"scatter\", \"uid\": \"0ab64927-aba1-4d64-acae-0e30d0eb38d7\"}], {\"title\": {\"text\": \"Test set accuracy of padded ELMo dataset with variable maximum lengths\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\")) {window._Plotly.Plots.resize(document.getElementById(\"ceb41446-7291-4831-b10b-bc7edf632382\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traces = elmo_rounds\n",
    "\n",
    "# Create traces\n",
    "def create_scatter(counter):\n",
    "    acc_dict = traces[counter]\n",
    "    \n",
    "    return go.Scatter(\n",
    "        x = list(acc_dict.keys()),\n",
    "        y = list(acc_dict.values()),\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Round ' + str(counter)\n",
    "    )\n",
    "\n",
    "trace_data = [create_scatter(trace) for trace in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Test set accuracy of padded ELMo dataset with variable maximum lengths',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = trace_data, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "fill": "tozerox",
         "fillcolor": "rgba(0,100,80,0.2)",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "name": "BERT",
         "showlegend": false,
         "type": "scatter",
         "uid": "dcf74d6a-dc4b-47af-aa65-7290dd96e8a2",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          35,
          34,
          33,
          32,
          31,
          30,
          29,
          28,
          27,
          26,
          25,
          24,
          23,
          22,
          21,
          20,
          19,
          18,
          17,
          16,
          15,
          14,
          13,
          12,
          11,
          10,
          9,
          8,
          7,
          6,
          5
         ],
         "y": [
          0.513043478637816,
          0.5122529648038239,
          0.5090909094207372,
          0.5090909091144682,
          0.5098814233018476,
          0.5122529647567056,
          0.5075098817998712,
          0.5146245063058001,
          0.505928854131887,
          0.5027667987488004,
          0.5106719368295707,
          0.5106719367824524,
          0.513043478637816,
          0.5122529648038239,
          0.5106719371358397,
          0.5177865616417685,
          0.5193675893097527,
          0.5256916999816894,
          0.5233201584797131,
          0.522529644645721,
          0.5169960478077764,
          0.521739130811729,
          0.5201581031437448,
          0.5154150201397922,
          0.5209486169777369,
          0.5169960478077764,
          0.5162055336203971,
          0.5154150201397922,
          0.5130434783315471,
          0.5154150201397922,
          0.5185770754286423,
          0.5067193679658791,
          0.49723320195797405,
          0.5043478264639029,
          0.5043478264639029,
          0.5011857711279345,
          0.5027667987959187,
          0.4996047434599503,
          0.505928854131887,
          0.5114624509698318,
          0.5106719367824524,
          0.505138340297895,
          0.5059288540847687,
          0.5106719368295707,
          0.5019762849619266,
          0.5106719371358397,
          0.5043478264167846,
          0.5051383402507766,
          0.5019762846085394,
          0.4956521739366026,
          0.49802371543857893,
          0.4996047431065631,
          0.488537549784061,
          0.4940711466220057,
          0.4996047434599503,
          0.49723320195797405,
          0.4996047434599503,
          0.49407114631573673,
          0.49090909128603727,
          0.4948616604559978,
          0.5027667984425315,
          0.49249011895402145
         ]
        },
        {
         "line": {
          "color": "rgb(0,100,80)"
         },
         "mode": "lines+markers",
         "name": "BERT",
         "type": "scatter",
         "uid": "6af4330d-88c0-46e9-8af4-397e4249f269",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.5048221346936207,
          0.5081422926550326,
          0.5021343876392003,
          0.5038735179703225,
          0.5027667985226326,
          0.5067193679564556,
          0.502924901482616,
          0.5065612651378271,
          0.5000790517414982,
          0.4932806327785899,
          0.5057707512237337,
          0.504822134410911,
          0.5037154153071844,
          0.5076679844158911,
          0.5081422927869638,
          0.5119367591807024,
          0.5141501979347274,
          0.5130434785671384,
          0.5168379449184705,
          0.51478260892182,
          0.5120948619757717,
          0.5162055339031069,
          0.5171541505038973,
          0.5092490121734,
          0.5098814233018476,
          0.5097233205350491,
          0.5098814230898153,
          0.5095652176975732,
          0.5089328065691258,
          0.5076679844959922,
          0.5109881425893354
         ]
        },
        {
         "fill": "tozerox",
         "fillcolor": "rgba(0,176,246,0.2)",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "name": "ELMo",
         "showlegend": false,
         "type": "scatter",
         "uid": "0f3f9e7f-5480-4b72-9c9c-b142638b91b0",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          35,
          34,
          33,
          32,
          31,
          30,
          29,
          28,
          27,
          26,
          25,
          24,
          23,
          22,
          21,
          20,
          19,
          18,
          17,
          16,
          15,
          14,
          13,
          12,
          11,
          10,
          9,
          8,
          7,
          6,
          5
         ],
         "y": [
          0.5177865616417685,
          0.5264822137685633,
          0.5146245062586818,
          0.5233201584325948,
          0.5138339924246897,
          0.5059288540847687,
          0.4988142295788399,
          0.5146245063058001,
          0.5011857710808162,
          0.5051383402036584,
          0.5083003955867451,
          0.5169960478077764,
          0.5154150200455556,
          0.5177865616417685,
          0.516205533926666,
          0.5185770754286423,
          0.5304347829385238,
          0.5312252967725158,
          0.5209486169306186,
          0.5138339924246897,
          0.5209486169306186,
          0.5233201584325948,
          0.5169960478077764,
          0.5201581030966265,
          0.5241106723137052,
          0.5185770754286423,
          0.5169960477606581,
          0.5146245063058001,
          0.5185770754286423,
          0.5138339924246897,
          0.5154150200926739,
          0.5035573125827925,
          0.499604743412832,
          0.5130434785906977,
          0.5090909094678555,
          0.5043478264167846,
          0.5098814233018476,
          0.5193675892626344,
          0.5130434785906977,
          0.505138340297895,
          0.5185770754757606,
          0.5138339924246897,
          0.5106719370887214,
          0.5011857710808162,
          0.5146245063058001,
          0.5067193679187609,
          0.5083003955867451,
          0.5059288540847687,
          0.513043478637816,
          0.5098814232547293,
          0.5067193679187609,
          0.4932806327408953,
          0.49723320191085574,
          0.49169960507291105,
          0.49090909123891896,
          0.49090909123891896,
          0.4996047434599503,
          0.505928854131887,
          0.5067193676124919,
          0.5114624509698318,
          0.5169960478077764,
          0.5122529647567056
         ]
        },
        {
         "line": {
          "color": "rgb(0,176,246)"
         },
         "mode": "lines+markers",
         "name": "ELMo",
         "type": "scatter",
         "uid": "2705188a-2538-4f76-bb6f-bd14d18d072c",
         "x": [
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          0.51541502010838,
          0.522529644614309,
          0.5135704878290651,
          0.5122529646546159,
          0.5088274048251126,
          0.5030303033758372,
          0.4959156788542023,
          0.5022397895418451,
          0.4956521742428716,
          0.5019762848991022,
          0.5027667987488005,
          0.511989460176787,
          0.5133069831863223,
          0.5151515155127554,
          0.5101449278503538,
          0.5133069832177345,
          0.5146245062586818,
          0.522529644614309,
          0.5109354417000521,
          0.5122529647567056,
          0.5172595523719888,
          0.5204216077393694,
          0.511198946342795,
          0.5169960477763642,
          0.5220026353916475,
          0.5151515154970493,
          0.5101449278660599,
          0.511989460176787,
          0.5164690385537029,
          0.5061923586960995,
          0.5096179186433986
         ]
        }
       ],
       "layout": {
        "paper_bgcolor": "rgb(255,255,255)",
        "plot_bgcolor": "rgb(229,229,229)",
        "title": {
         "text": "Test set accuracy of padded datasets with variable maximum lengths"
        },
        "xaxis": {
         "gridcolor": "rgb(255,255,255)",
         "range": [
          5,
          35
         ],
         "showgrid": true,
         "showline": false,
         "showticklabels": true,
         "tickcolor": "rgb(127,127,127)",
         "ticks": "outside",
         "zeroline": false
        },
        "yaxis": {
         "gridcolor": "rgb(255,255,255)",
         "showgrid": true,
         "showline": false,
         "showticklabels": true,
         "tickcolor": "rgb(127,127,127)",
         "ticks": "outside",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"d168741c-8320-4c3c-85d3-c8a7104bdba5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\")) {\n",
       "    Plotly.newPlot(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\", [{\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,100,80,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"BERT\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.513043478637816, 0.5122529648038239, 0.5090909094207372, 0.5090909091144682, 0.5098814233018476, 0.5122529647567056, 0.5075098817998712, 0.5146245063058001, 0.505928854131887, 0.5027667987488004, 0.5106719368295707, 0.5106719367824524, 0.513043478637816, 0.5122529648038239, 0.5106719371358397, 0.5177865616417685, 0.5193675893097527, 0.5256916999816894, 0.5233201584797131, 0.522529644645721, 0.5169960478077764, 0.521739130811729, 0.5201581031437448, 0.5154150201397922, 0.5209486169777369, 0.5169960478077764, 0.5162055336203971, 0.5154150201397922, 0.5130434783315471, 0.5154150201397922, 0.5185770754286423, 0.5067193679658791, 0.49723320195797405, 0.5043478264639029, 0.5043478264639029, 0.5011857711279345, 0.5027667987959187, 0.4996047434599503, 0.505928854131887, 0.5114624509698318, 0.5106719367824524, 0.505138340297895, 0.5059288540847687, 0.5106719368295707, 0.5019762849619266, 0.5106719371358397, 0.5043478264167846, 0.5051383402507766, 0.5019762846085394, 0.4956521739366026, 0.49802371543857893, 0.4996047431065631, 0.488537549784061, 0.4940711466220057, 0.4996047434599503, 0.49723320195797405, 0.4996047434599503, 0.49407114631573673, 0.49090909128603727, 0.4948616604559978, 0.5027667984425315, 0.49249011895402145], \"type\": \"scatter\", \"uid\": \"dcf74d6a-dc4b-47af-aa65-7290dd96e8a2\"}, {\"line\": {\"color\": \"rgb(0,100,80)\"}, \"mode\": \"lines+markers\", \"name\": \"BERT\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5048221346936207, 0.5081422926550326, 0.5021343876392003, 0.5038735179703225, 0.5027667985226326, 0.5067193679564556, 0.502924901482616, 0.5065612651378271, 0.5000790517414982, 0.4932806327785899, 0.5057707512237337, 0.504822134410911, 0.5037154153071844, 0.5076679844158911, 0.5081422927869638, 0.5119367591807024, 0.5141501979347274, 0.5130434785671384, 0.5168379449184705, 0.51478260892182, 0.5120948619757717, 0.5162055339031069, 0.5171541505038973, 0.5092490121734, 0.5098814233018476, 0.5097233205350491, 0.5098814230898153, 0.5095652176975732, 0.5089328065691258, 0.5076679844959922, 0.5109881425893354], \"type\": \"scatter\", \"uid\": \"6af4330d-88c0-46e9-8af4-397e4249f269\"}, {\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,176,246,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"ELMo\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.5177865616417685, 0.5264822137685633, 0.5146245062586818, 0.5233201584325948, 0.5138339924246897, 0.5059288540847687, 0.4988142295788399, 0.5146245063058001, 0.5011857710808162, 0.5051383402036584, 0.5083003955867451, 0.5169960478077764, 0.5154150200455556, 0.5177865616417685, 0.516205533926666, 0.5185770754286423, 0.5304347829385238, 0.5312252967725158, 0.5209486169306186, 0.5138339924246897, 0.5209486169306186, 0.5233201584325948, 0.5169960478077764, 0.5201581030966265, 0.5241106723137052, 0.5185770754286423, 0.5169960477606581, 0.5146245063058001, 0.5185770754286423, 0.5138339924246897, 0.5154150200926739, 0.5035573125827925, 0.499604743412832, 0.5130434785906977, 0.5090909094678555, 0.5043478264167846, 0.5098814233018476, 0.5193675892626344, 0.5130434785906977, 0.505138340297895, 0.5185770754757606, 0.5138339924246897, 0.5106719370887214, 0.5011857710808162, 0.5146245063058001, 0.5067193679187609, 0.5083003955867451, 0.5059288540847687, 0.513043478637816, 0.5098814232547293, 0.5067193679187609, 0.4932806327408953, 0.49723320191085574, 0.49169960507291105, 0.49090909123891896, 0.49090909123891896, 0.4996047434599503, 0.505928854131887, 0.5067193676124919, 0.5114624509698318, 0.5169960478077764, 0.5122529647567056], \"type\": \"scatter\", \"uid\": \"0f3f9e7f-5480-4b72-9c9c-b142638b91b0\"}, {\"line\": {\"color\": \"rgb(0,176,246)\"}, \"mode\": \"lines+markers\", \"name\": \"ELMo\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.51541502010838, 0.522529644614309, 0.5135704878290651, 0.5122529646546159, 0.5088274048251126, 0.5030303033758372, 0.4959156788542023, 0.5022397895418451, 0.4956521742428716, 0.5019762848991022, 0.5027667987488005, 0.511989460176787, 0.5133069831863223, 0.5151515155127554, 0.5101449278503538, 0.5133069832177345, 0.5146245062586818, 0.522529644614309, 0.5109354417000521, 0.5122529647567056, 0.5172595523719888, 0.5204216077393694, 0.511198946342795, 0.5169960477763642, 0.5220026353916475, 0.5151515154970493, 0.5101449278660599, 0.511989460176787, 0.5164690385537029, 0.5061923586960995, 0.5096179186433986], \"type\": \"scatter\", \"uid\": \"2705188a-2538-4f76-bb6f-bd14d18d072c\"}], {\"paper_bgcolor\": \"rgb(255,255,255)\", \"plot_bgcolor\": \"rgb(229,229,229)\", \"title\": {\"text\": \"Test set accuracy of padded datasets with variable maximum lengths\"}, \"xaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"range\": [5, 35], \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}, \"yaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\")) {window._Plotly.Plots.resize(document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"d168741c-8320-4c3c-85d3-c8a7104bdba5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\")) {\n",
       "    Plotly.newPlot(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\", [{\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,100,80,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"BERT\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.513043478637816, 0.5122529648038239, 0.5090909094207372, 0.5090909091144682, 0.5098814233018476, 0.5122529647567056, 0.5075098817998712, 0.5146245063058001, 0.505928854131887, 0.5027667987488004, 0.5106719368295707, 0.5106719367824524, 0.513043478637816, 0.5122529648038239, 0.5106719371358397, 0.5177865616417685, 0.5193675893097527, 0.5256916999816894, 0.5233201584797131, 0.522529644645721, 0.5169960478077764, 0.521739130811729, 0.5201581031437448, 0.5154150201397922, 0.5209486169777369, 0.5169960478077764, 0.5162055336203971, 0.5154150201397922, 0.5130434783315471, 0.5154150201397922, 0.5185770754286423, 0.5067193679658791, 0.49723320195797405, 0.5043478264639029, 0.5043478264639029, 0.5011857711279345, 0.5027667987959187, 0.4996047434599503, 0.505928854131887, 0.5114624509698318, 0.5106719367824524, 0.505138340297895, 0.5059288540847687, 0.5106719368295707, 0.5019762849619266, 0.5106719371358397, 0.5043478264167846, 0.5051383402507766, 0.5019762846085394, 0.4956521739366026, 0.49802371543857893, 0.4996047431065631, 0.488537549784061, 0.4940711466220057, 0.4996047434599503, 0.49723320195797405, 0.4996047434599503, 0.49407114631573673, 0.49090909128603727, 0.4948616604559978, 0.5027667984425315, 0.49249011895402145], \"type\": \"scatter\", \"uid\": \"dcf74d6a-dc4b-47af-aa65-7290dd96e8a2\"}, {\"line\": {\"color\": \"rgb(0,100,80)\"}, \"mode\": \"lines+markers\", \"name\": \"BERT\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.5048221346936207, 0.5081422926550326, 0.5021343876392003, 0.5038735179703225, 0.5027667985226326, 0.5067193679564556, 0.502924901482616, 0.5065612651378271, 0.5000790517414982, 0.4932806327785899, 0.5057707512237337, 0.504822134410911, 0.5037154153071844, 0.5076679844158911, 0.5081422927869638, 0.5119367591807024, 0.5141501979347274, 0.5130434785671384, 0.5168379449184705, 0.51478260892182, 0.5120948619757717, 0.5162055339031069, 0.5171541505038973, 0.5092490121734, 0.5098814233018476, 0.5097233205350491, 0.5098814230898153, 0.5095652176975732, 0.5089328065691258, 0.5076679844959922, 0.5109881425893354], \"type\": \"scatter\", \"uid\": \"6af4330d-88c0-46e9-8af4-397e4249f269\"}, {\"fill\": \"tozerox\", \"fillcolor\": \"rgba(0,176,246,0.2)\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"name\": \"ELMo\", \"showlegend\": false, \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5], \"y\": [0.5177865616417685, 0.5264822137685633, 0.5146245062586818, 0.5233201584325948, 0.5138339924246897, 0.5059288540847687, 0.4988142295788399, 0.5146245063058001, 0.5011857710808162, 0.5051383402036584, 0.5083003955867451, 0.5169960478077764, 0.5154150200455556, 0.5177865616417685, 0.516205533926666, 0.5185770754286423, 0.5304347829385238, 0.5312252967725158, 0.5209486169306186, 0.5138339924246897, 0.5209486169306186, 0.5233201584325948, 0.5169960478077764, 0.5201581030966265, 0.5241106723137052, 0.5185770754286423, 0.5169960477606581, 0.5146245063058001, 0.5185770754286423, 0.5138339924246897, 0.5154150200926739, 0.5035573125827925, 0.499604743412832, 0.5130434785906977, 0.5090909094678555, 0.5043478264167846, 0.5098814233018476, 0.5193675892626344, 0.5130434785906977, 0.505138340297895, 0.5185770754757606, 0.5138339924246897, 0.5106719370887214, 0.5011857710808162, 0.5146245063058001, 0.5067193679187609, 0.5083003955867451, 0.5059288540847687, 0.513043478637816, 0.5098814232547293, 0.5067193679187609, 0.4932806327408953, 0.49723320191085574, 0.49169960507291105, 0.49090909123891896, 0.49090909123891896, 0.4996047434599503, 0.505928854131887, 0.5067193676124919, 0.5114624509698318, 0.5169960478077764, 0.5122529647567056], \"type\": \"scatter\", \"uid\": \"0f3f9e7f-5480-4b72-9c9c-b142638b91b0\"}, {\"line\": {\"color\": \"rgb(0,176,246)\"}, \"mode\": \"lines+markers\", \"name\": \"ELMo\", \"x\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], \"y\": [0.51541502010838, 0.522529644614309, 0.5135704878290651, 0.5122529646546159, 0.5088274048251126, 0.5030303033758372, 0.4959156788542023, 0.5022397895418451, 0.4956521742428716, 0.5019762848991022, 0.5027667987488005, 0.511989460176787, 0.5133069831863223, 0.5151515155127554, 0.5101449278503538, 0.5133069832177345, 0.5146245062586818, 0.522529644614309, 0.5109354417000521, 0.5122529647567056, 0.5172595523719888, 0.5204216077393694, 0.511198946342795, 0.5169960477763642, 0.5220026353916475, 0.5151515154970493, 0.5101449278660599, 0.511989460176787, 0.5164690385537029, 0.5061923586960995, 0.5096179186433986], \"type\": \"scatter\", \"uid\": \"2705188a-2538-4f76-bb6f-bd14d18d072c\"}], {\"paper_bgcolor\": \"rgb(255,255,255)\", \"plot_bgcolor\": \"rgb(229,229,229)\", \"title\": {\"text\": \"Test set accuracy of padded datasets with variable maximum lengths\"}, \"xaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"range\": [5, 35], \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}, \"yaxis\": {\"gridcolor\": \"rgb(255,255,255)\", \"showgrid\": true, \"showline\": false, \"showticklabels\": true, \"tickcolor\": \"rgb(127,127,127)\", \"ticks\": \"outside\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\")) {window._Plotly.Plots.resize(document.getElementById(\"d168741c-8320-4c3c-85d3-c8a7104bdba5\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(5, 36))\n",
    "x_rev = x[::-1]\n",
    "\n",
    "# BERT\n",
    "bert_matrix = np.transpose(np.array([np.array(list(acc_round.values())) for acc_round in bert_rounds]))\n",
    "bert_y = [np.average(row) for row in bert_matrix]\n",
    "bert_y_upper = [row.max() for row in bert_matrix]\n",
    "bert_y_lower = [row.min() for row in bert_matrix]\n",
    "bert_y_lower = bert_y_lower[::-1]\n",
    "\n",
    "bert1 = go.Scatter(\n",
    "    x = x + x_rev,\n",
    "    y = bert_y_upper + bert_y_lower,\n",
    "    fill = 'tozerox',\n",
    "    fillcolor = 'rgba(0,100,80,0.2)',\n",
    "    line = dict(color = 'rgba(255,255,255,0)'),\n",
    "    showlegend = False,\n",
    "    name = 'BERT',\n",
    ")\n",
    "bert2 = go.Scatter(\n",
    "    x = x,\n",
    "    y = bert_y,\n",
    "    line = dict(color='rgb(0,100,80)'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'BERT',\n",
    ")\n",
    "\n",
    "# ELMo\n",
    "elmo_matrix = np.transpose(np.array([np.array(list(acc_round.values())) for acc_round in elmo_rounds]))\n",
    "elmo_y = [np.average(row) for row in elmo_matrix]\n",
    "elmo_y_upper = [row.max() for row in elmo_matrix]\n",
    "elmo_y_lower = [row.min() for row in elmo_matrix]\n",
    "elmo_y_lower = elmo_y_lower[::-1]\n",
    "\n",
    "elmo1 = go.Scatter(\n",
    "    x = x + x_rev,\n",
    "    y = elmo_y_upper + elmo_y_lower,\n",
    "    fill = 'tozerox',\n",
    "    fillcolor = 'rgba(0,176,246,0.2)',\n",
    "    line = dict(color = 'rgba(255,255,255,0)'),\n",
    "    showlegend = False,\n",
    "    name = 'ELMo',\n",
    ")\n",
    "elmo2 = go.Scatter(\n",
    "    x = x,\n",
    "    y = elmo_y,\n",
    "    line = dict(color='rgb(0,176,246)'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'ELMo',\n",
    ")\n",
    "\n",
    "\n",
    "data = [bert1, bert2, elmo1, elmo2]\n",
    "layout = go.Layout(\n",
    "    title = 'Test set accuracy of padded datasets with variable maximum lengths',\n",
    "    paper_bgcolor = 'rgb(255,255,255)',\n",
    "    plot_bgcolor = 'rgb(229,229,229)',\n",
    "    xaxis = dict(\n",
    "        gridcolor = 'rgb(255,255,255)',\n",
    "        range = [5,35],\n",
    "        showgrid = True,\n",
    "        showline = False,\n",
    "        showticklabels = True,\n",
    "        tickcolor = 'rgb(127,127,127)',\n",
    "        ticks = 'outside',\n",
    "        zeroline = False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        gridcolor='rgb(255,255,255)',\n",
    "        showgrid = True,\n",
    "        showline = False,\n",
    "        showticklabels = True,\n",
    "        tickcolor = 'rgb(127,127,127)',\n",
    "        ticks = 'outside',\n",
    "        zeroline = False\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_score(X_train, X_test, X_validation, y_train = general['train']['label'], y_test = general['test']['label'], y_validation = general['validation']['label'], reshape = True):\n",
    "    # Rearrange data types    \n",
    "    params = locals().copy()    \n",
    "    inputs = {\n",
    "        dataset: np.array(params[dataset])\n",
    "        for dataset in params.keys()\n",
    "    }\n",
    "    \n",
    "    # Reshape datasets\n",
    "    for dataset in inputs.keys():\n",
    "        if dataset[0:1] == 'X':\n",
    "            if reshape:\n",
    "                inputs[dataset] = np.reshape(inputs[dataset], (inputs[dataset].shape[0], inputs[dataset].shape[1], 1))\n",
    "            \n",
    "        elif dataset[0:1] == 'y':\n",
    "            inputs[dataset] = np_utils.to_categorical(np.array(inputs[dataset]), 3)\n",
    "            \n",
    "    # Set model parameters\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    input_shape =  inputs['X_train'].shape\n",
    "    print(input_shape)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, kernel_size = 2, activation='relu', input_shape = (input_shape[1], input_shape[2]), data_format = 'channels_first'))\n",
    "    model.add(Conv1D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(Conv1D(128, kernel_size = 4, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile('sgd', 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    \n",
    "    # Fit the training set over the model and correct on the validation set\n",
    "    model.fit(inputs['X_train'], inputs['y_train'],\n",
    "            batch_size = batch_size,\n",
    "            epochs = epochs,\n",
    "            validation_data = (inputs['X_validation'], inputs['y_validation']))\n",
    "    \n",
    "    # Get score over the test set\n",
    "    score, acc = model.evaluate(inputs['X_test'], inputs['y_test'])\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_bert = {\n",
    "    dataset: [np.concatenate(np.array(statement)) for statement in bert[dataset].statement]\n",
    "    for dataset in bert.keys()\n",
    "}\n",
    "\n",
    "padded_bert = {\n",
    "    fold: sequence.pad_sequences(concatenated_bert[fold], maxlen = 22, dtype = float)\n",
    "    for fold in concatenated_bert.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10235, 5, 3072)\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-06-04 08:30:54,068 From /Users/martijn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2019-06-04 08:30:54,211 From /Users/martijn/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10235 samples, validate on 1284 samples\n",
      "Epoch 1/5\n",
      "10235/10235 [==============================] - 123s 12ms/step - loss: 1.0606 - acc: 0.4437 - val_loss: 1.0184 - val_acc: 0.5078\n",
      "Epoch 2/5\n",
      "10235/10235 [==============================] - 120s 12ms/step - loss: 1.0429 - acc: 0.4692 - val_loss: 1.0110 - val_acc: 0.5109\n",
      "Epoch 3/5\n",
      "10235/10235 [==============================] - 144s 14ms/step - loss: 1.0313 - acc: 0.4830 - val_loss: 1.0142 - val_acc: 0.5125\n",
      "Epoch 4/5\n",
      "10235/10235 [==============================] - 229s 22ms/step - loss: 1.0212 - acc: 0.4932 - val_loss: 1.0051 - val_acc: 0.5187\n",
      "Epoch 5/5\n",
      "10235/10235 [==============================] - 205s 20ms/step - loss: 1.0117 - acc: 0.5031 - val_loss: 1.0002 - val_acc: 0.5132\n",
      "1265/1265 [==============================] - 8s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49090909128603727"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cnn_score(padded_bert['train'], padded_bert['test'], padded_bert['validation'], reshape = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_round(dataset):\n",
    "    # Store accuracies\n",
    "    accuracies = {\n",
    "        padding_len: 0.0 for padding_len in list(range(5,36))\n",
    "    }\n",
    "\n",
    "    for max_len in accuracies.keys():\n",
    "        padded_dataset = {\n",
    "            fold: sequence.pad_sequences(dataset[fold], maxlen = max_len, dtype = float)\n",
    "            for fold in dataset.keys()\n",
    "        }\n",
    "        print(max_len)\n",
    "        accuracies[max_len] = get_cnn_score(padded_dataset['train'], padded_dataset['test'], padded_dataset['validation'], reshape = False)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 4 from 2 for 'conv1d_6/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,2,128], [1,4,128,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 4 from 2 for 'conv1d_6/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,2,128], [1,4,128,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1db9af46cadd>\u001b[0m in \u001b[0;36mcalculate_round\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     11\u001b[0m         }\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9069a88dddbb>\u001b[0m in \u001b[0;36mget_cnn_score\u001b[0;34m(X_train, X_test, X_validation, y_train, y_test, y_validation, reshape)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 dilation_rate=self.dilation_rate[0])\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             outputs = K.conv2d(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3609\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3611\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         data_format=data_format)\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv1d\u001b[0;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   3480\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m         data_format=data_format)\n\u001b[0m\u001b[1;32m   3483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1027\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 4 from 2 for 'conv1d_6/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,2,128], [1,4,128,128]."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cnn_bert_rounds = [calculate_round(concatenated_bert) for round in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### References\n",
    "\n",
    "```\n",
    "@article{DBLP:journals/corr/Wang17j,\n",
    "  author    = {William Yang Wang},\n",
    "  title     = {\"Liar, Liar Pants on Fire\": {A} New Benchmark Dataset for Fake News\n",
    "               Detection},\n",
    "  journal   = {CoRR},\n",
    "  volume    = {abs/1705.00648},\n",
    "  year      = {2017},\n",
    "  url       = {http://arxiv.org/abs/1705.00648},\n",
    "  archivePrefix = {arXiv},\n",
    "  eprint    = {1705.00648},\n",
    "  timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},\n",
    "  biburl    = {https://dblp.org/rec/bib/journals/corr/Wang17j},\n",
    "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
