{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning vectors into a fixed length\n",
    "The statements in the Liar dataset do not hold a fixed length needed as input for machine learning algorithms. This means that the vectors generated from the different embedding techniques vary in length and need to be generalized to a fixed length. \n",
    "In this notebook, the first research question will be answered: *which way of reshaping vectors to a fixed length works best for classifying fake news?*\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Exploring the options\n",
    "In computer vision, feature pooling is used to reduce noise in data. The goal of this step is to transform joint feature representation into a new, more usable one that preserves important information while discarding irrelevant details. Pooling techniques such as max pooling and average pooling perform mathematical operations to reduce several numbers into one [(Boureau et al., 2010)](https://www.di.ens.fr/willow/pdfs/icml2010b.pdf). In the case of transforming the shape of the data, we can reduce vectors to the smallest vector in the dataset to create a uniform shape.\n",
    "\n",
    "Instead of reducing longer vectors to the smallest size, we can decide to do the opposite, and take the biggest vector and reshape smaller ones to the shape of the vector with the biggest length. This technique called *padding* is also a way of gaining a fixed vector shape for our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from hypopt import GridSearch\n",
    "\n",
    "# Set offline mode for plotly\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "# The DataLoader class gives access to pretrained vectors from the Liar dataset\n",
    "from data_loader import DataLoader\n",
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Sentence embeddings\n",
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating InferSent representation and saving them as files...\n",
      "[nltk_data] Downloading package punkt to /Users/martijn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Found 15916(/16722) words with w2v vectors\n",
      "Vocab size : 15916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martijn/Documents/BachelorThesis/code/data_loader.py:174: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "general = data.get_dfs()\n",
    "infersent = data.get_infersent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying shaping techniques\n",
    "#### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(statement):\n",
    "    if len(statement) > 1:\n",
    "        return [row.max() for row in np.transpose([[token_row.max() for token_row in np.transpose(np.array(sentence))] for sentence in statement])]\n",
    "    else:\n",
    "        return [token_row.max() for token_row in np.transpose(statement[0])]\n",
    "\n",
    "max_pooled_infersent = {\n",
    "    dataset: infersent[dataset].statement.apply(lambda statement: max_pool(statement))\n",
    "    for dataset in infersent.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_pool(statement):\n",
    "    if len(statement) > 1:\n",
    "        return [row.min() for row in np.transpose([[token_row.min() for token_row in np.transpose(np.array(sentence))] for sentence in statement])]\n",
    "    else:\n",
    "        return [token_row.min() for token_row in np.transpose(statement[0])]\n",
    "\n",
    "min_pooled_infersent = {\n",
    "    dataset: infersent[dataset].statement.apply(lambda statement: min_pool(statement))\n",
    "    for dataset in infersent.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(statement):\n",
    "    if len(statement) > 1:\n",
    "        return [np.average(row) for row in np.transpose([[np.average(token_row) for token_row in np.transpose(np.array(sentence))] for sentence in statement])]\n",
    "    else:\n",
    "        return [np.average(token_row) for token_row in np.transpose(statement[0])]\n",
    "\n",
    "average_pooled_infersent = {\n",
    "    dataset: infersent[dataset].statement.apply(lambda statement: average_pool(statement))\n",
    "    for dataset in infersent.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_infersent = {\n",
    "    dataset: infersent[dataset].statement.apply(lambda statement: np.concatenate([item.flatten() for item in statement]))\n",
    "    for dataset in infersent.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_set = pd.concat([combined_infersent['train'], combined_infersent['test'], combined_infersent['validation']]).apply(lambda vector: len(vector))\n",
    "seq_n = whole_set.median()\n",
    "seq_std = whole_set.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total percentage of statements below the threshold: 80.88235294117648\n"
     ]
    }
   ],
   "source": [
    "print('The total percentage of statements below the threshold:', len(whole_set.where(whole_set <= seq_n + seq_std).dropna()) / len(whole_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median and two times the standard deviation gets us the almost 95% of the tokens\n",
    "max_length = int(seq_n + seq_std)\n",
    "\n",
    "padded_infersent = {\n",
    "    dataset: pad_sequences(infersent[dataset].statement.apply(lambda statement: np.concatenate([item.flatten() for item in statement])), maxlen = max_length)\n",
    "    for dataset in infersent.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying classifiers\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = data.get_dfs()\n",
    "\n",
    "# Recode labels from 6 to 3\n",
    "def recode(label):\n",
    "    if label == 'false' or label == 'pants-fire' or label == 'barely-true':\n",
    "        return 'false'\n",
    "    elif label == 'true' or label == 'mostly-true':\n",
    "        return 'true'\n",
    "    elif label == 'half-true':\n",
    "        return 'half-true'\n",
    "\n",
    "for dataset in general.keys():\n",
    "    general[dataset]['label'] = general[dataset]['label'].apply(lambda label: recode(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logres_score(X_train, X_test, X_validation, y_train = general['train']['label'], y_test = general['test']['label'], y_validation = general['validation']['label']):\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "    gs = GridSearch(model = LogisticRegression(), param_grid = param_grid)\n",
    "    gs.fit(X_train, y_train, X_validation, y_validation)\n",
    "    \n",
    "    return gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4853754940711462"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logres_score(max_pooled_infersent['train'], max_pooled_infersent['test'], max_pooled_infersent['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43715415019762843"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logres_score(min_pooled_infersent['train'], min_pooled_infersent['test'], min_pooled_infersent['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46561264822134385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logres_score(average_pooled_infersent['train'], average_pooled_infersent['test'], average_pooled_infersent['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "InferSent",
         "type": "bar",
         "uid": "d28f9b42-3967-4b74-808d-979f318a660c",
         "x": [
          "Max pooling",
          "Average pooling",
          "Min pooling",
          "Padding"
         ],
         "y": [
          0.4853754940711462,
          0.46561264822134385,
          0.43715415019762843,
          0
         ]
        },
        {
         "name": "ELMo",
         "type": "bar",
         "uid": "c6431be4-5593-4bb4-9bb5-8aea88219254",
         "x": [
          "Max pooling",
          "Average pooling",
          "Min pooling",
          "Padding"
         ],
         "y": [
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "barmode": "group"
       }
      },
      "text/html": [
       "<div id=\"87b2792f-0a35-451a-af56-8c2e99635c5e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\")) {\n",
       "    Plotly.newPlot(\"87b2792f-0a35-451a-af56-8c2e99635c5e\", [{\"name\": \"InferSent\", \"x\": [\"Max pooling\", \"Average pooling\", \"Min pooling\", \"Padding\"], \"y\": [0.4853754940711462, 0.46561264822134385, 0.43715415019762843, 0.0], \"type\": \"bar\", \"uid\": \"d28f9b42-3967-4b74-808d-979f318a660c\"}, {\"name\": \"ELMo\", \"x\": [\"Max pooling\", \"Average pooling\", \"Min pooling\", \"Padding\"], \"y\": [0.0, 0.0, 0.0, 0.0], \"type\": \"bar\", \"uid\": \"c6431be4-5593-4bb4-9bb5-8aea88219254\"}], {\"barmode\": \"group\"}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\")) {window._Plotly.Plots.resize(document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"87b2792f-0a35-451a-af56-8c2e99635c5e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\")) {\n",
       "    Plotly.newPlot(\"87b2792f-0a35-451a-af56-8c2e99635c5e\", [{\"name\": \"InferSent\", \"x\": [\"Max pooling\", \"Average pooling\", \"Min pooling\", \"Padding\"], \"y\": [0.4853754940711462, 0.46561264822134385, 0.43715415019762843, 0.0], \"type\": \"bar\", \"uid\": \"d28f9b42-3967-4b74-808d-979f318a660c\"}, {\"name\": \"ELMo\", \"x\": [\"Max pooling\", \"Average pooling\", \"Min pooling\", \"Padding\"], \"y\": [0.0, 0.0, 0.0, 0.0], \"type\": \"bar\", \"uid\": \"c6431be4-5593-4bb4-9bb5-8aea88219254\"}], {\"barmode\": \"group\"}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\")) {window._Plotly.Plots.resize(document.getElementById(\"87b2792f-0a35-451a-af56-8c2e99635c5e\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infersent_data = go.Bar(\n",
    "    x = ['Max pooling', 'Average pooling', 'Min pooling', 'Padding'],\n",
    "    y = [0.4853754940711462, 0.46561264822134385, 0.43715415019762843, 0.0],\n",
    "    name = 'InferSent'\n",
    ")\n",
    "\n",
    "elmo_data = go.Bar(\n",
    "    x = ['Max pooling', 'Average pooling', 'Min pooling', 'Padding'],\n",
    "    y = [0.0, 0.0, 0.0, 0.0],\n",
    "    name = 'ELMo'\n",
    ")\n",
    "\n",
    "data = [infersent_data, elmo_data]\n",
    "layout = go.Layout(\n",
    "    barmode = 'group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### References\n",
    "\n",
    "```\n",
    "@inproceedings{boureau2010theoretical,\n",
    "  title={A theoretical analysis of feature pooling in visual recognition},\n",
    "  author={Boureau, Y-Lan and Ponce, Jean and LeCun, Yann},\n",
    "  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},\n",
    "  pages={111--118},\n",
    "  year={2010}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
