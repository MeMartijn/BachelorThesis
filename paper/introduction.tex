In the pre-Internet era, the ability to broadcast information on a large scale was in the hands of large publishing organizations. 
Nowadays, everyone can share news and information via social media with the possibility of reaching a large, global audience \cite{howell2013}. 
This introduces risks on validity and authenticity of news, as social media and digital platforms can speed up the spread of falsehoods without requiring much effort from the author \cite{europeancommission2018}. 

As a matter of fact, 63\% of adults in the United States prefer to read their news on the Internet. 
Young adults take the lead: 76\% of adults between the ages 18 and 49 get their primary news consumption via the web, compared to just 43\% for adults of 50 years and older \cite{mitchell2018}.
As time passes by, social media is slowly becoming the primary source of news for more and more people. 

The main danger of this development is that human perception is often skewed with regards to objectivity of facts. 
Psychological human traits such as na√Øve realism let consumers of news belief that their perception is right, while other's perceptions are uninformed. 
Furthermore, confirmation bias results in consumers preferring information that confirms beliefs they already have \cite{shu2017}. 
This makes consumers vulnerable for the spread of misinformation or fake news. 

According to the European Commission, \textit{"disinformation - or fake news - consists of verifiably false or misleading information that is created, presented and disseminated for economic gain or to intentionally deceive the public, and may cause public harm"} \cite{europeancommission2018}. 
The answer to the problem of fake news as of recently has been to manually fact-check statements on validity, but, as Shu et al. underlines, one of the downsides to this approach is that fake news typically relates to newly emerging, time-critical events. 
This means the real news may not be fully verified by proper knowledge bases due to a lack of contradicting claims \cite{shu2017}. 
An automated approach would both help in solving the problem of human subjectivity and the speed at which false information is spread in the current news consumption landscape.
Furthermore, such an approach can help human fact-checking by targetting statements that are most likely to be false.

Natural language processing has been in rapid development over the past years. 
With the releases of OpenAI's GPT-2 model in February of this year and Google's BERT in the autumn of 2018, state-of-the-art pre-trained textual embedding techniques have shown promising results on various classification tasks \cite{radford2019}\cite{devlin2018}. 
Although fake news classification has been attempted before \cite{wang2018}\cite{khurana2017}, performance on these classifiers has been rather low. 
However, these new pre-trained textual embeddings have not yet been used in the fight against disinformation. 

This paper is focussed on the following research question: \textit{what is the performance of combinations of pre-trained embedding techniques with machine learning algorithms when classifying fake news?}
This main question will be answered through the results of the following subquestions:

\begin{description}
\item[RQ1] Which way of pooling vectors to a fixed length works best for classifying fake news?
\item[RQ2] At what maximum sequence length do neural networks hold the highest accuracy when classifying fake news?
\item[RQ3] How well do neural network classification architectures classify fake news compared to non-neural classification algorithms?
\end{description}

The structure of this paper will be as follows: first, related work regarding fake news detection, pre-trained word embeddings and preparing text for classification will be discussed.
Then, the methodology will be laid out, including throughout explanation of our pre-trained embedding methods. 
To conclude, these embedding techniques will be applied to the Liar dataset and classification results will be shared.